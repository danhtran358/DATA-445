{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dde354f",
   "metadata": {},
   "source": [
    "# 1.f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d158ea",
   "metadata": {},
   "source": [
    "# 2. I'm not sure if the the errors are absolute or relative. If all of the scenarios are acceptable, I would choose scenario 1.\n",
    "# This scenario does not have the best ratio between traning error and validation error, worse than scenario 2 only,\n",
    "# but the complexity is less because the depth of the tree is only 2 (use Occam's razor principle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f163c593",
   "metadata": {},
   "source": [
    "# 3. AdaBoost reweighs the weights of observations to force the new learners focus on the observations misclassified by previous learners.\n",
    "# Gradient Boosting uses the gradient of loss function to push the estimator to the parameter that achieve the minima of the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985ab1bf",
   "metadata": {},
   "source": [
    "# 4. No. Depending on the adjustment of hyper-parameters, any model can overfit or underfit the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d715e45",
   "metadata": {},
   "source": [
    "# 5.a Random forest does not have a learning rate parameter since the learners are dependent. AdaBoost did not have it in the orginal proposal but was implemented afterward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "107f8994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>currentSmoker</th>\n",
       "      <th>cigsPerDay</th>\n",
       "      <th>BPMeds</th>\n",
       "      <th>prevalentStroke</th>\n",
       "      <th>prevalentHyp</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>totChol</th>\n",
       "      <th>sysBP</th>\n",
       "      <th>diaBP</th>\n",
       "      <th>BMI</th>\n",
       "      <th>heartRate</th>\n",
       "      <th>glucose</th>\n",
       "      <th>TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.97</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>28.73</td>\n",
       "      <td>95.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>127.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25.34</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>28.58</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>23.10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   male  age  education  currentSmoker  cigsPerDay  BPMeds  prevalentStroke  \\\n",
       "0     1   39        4.0              0         0.0     0.0                0   \n",
       "1     0   46        2.0              0         0.0     0.0                0   \n",
       "2     1   48        1.0              1        20.0     0.0                0   \n",
       "3     0   61        3.0              1        30.0     0.0                0   \n",
       "4     0   46        3.0              1        23.0     0.0                0   \n",
       "\n",
       "   prevalentHyp  diabetes  totChol  sysBP  diaBP    BMI  heartRate  glucose  \\\n",
       "0             0         0    195.0  106.0   70.0  26.97       80.0     77.0   \n",
       "1             0         0    250.0  121.0   81.0  28.73       95.0     76.0   \n",
       "2             0         0    245.0  127.5   80.0  25.34       75.0     70.0   \n",
       "3             1         0    225.0  150.0   95.0  28.58       65.0    103.0   \n",
       "4             0         0    285.0  130.0   84.0  23.10       85.0     85.0   \n",
       "\n",
       "   TenYearCHD  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           1  \n",
       "4           0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 6.a\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "## Defining the bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'danhtran358-data-445-bucket'\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "## Defining the csv file\n",
    "file_key = 'framingham.csv'\n",
    "\n",
    "bucket_object = bucket.Object(file_key)\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "## Reading the csv file\n",
    "heart = pd.read_csv(file_content_stream)\n",
    "heart = heart.dropna()\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce60d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining input and target variables\n",
    "X = heart[['age', 'totChol', 'sysBP', 'BMI', 'heartRate', 'glucose']]\n",
    "Y = heart['TenYearCHD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3afb9ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to get recall from random forest model\n",
    "def get_scores_rf(X_train, X_test, Y_train, Y_test):\n",
    "    ## Random forest model\n",
    "    md_rf = RandomForestClassifier(max_depth = 3, n_estimators = 500).fit(X_train, Y_train)\n",
    "    \n",
    "    ## Predict and classfify\n",
    "    pred_rf = md_rf.predict_proba(X_test)[:,1]\n",
    "    pred_rf = np.where(pred_rf < 0.1, 0, 1)\n",
    "    \n",
    "    ## Calculate recall score and return\n",
    "    return recall_score(Y_test, pred_rf), accuracy_score(Y_test, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "551c348d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to get recall from AdaBoost model with Decision tree\n",
    "def get_scores_ada(X_train, X_test, Y_train, Y_test):\n",
    "    ## Adaboost model with Decision Tree leaners\n",
    "    md_ada = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = 3), n_estimators = 500, learning_rate = 0.01).fit(X_train, Y_train)\n",
    "    \n",
    "    ## Predict and classfify\n",
    "    pred_ada = md_ada.predict_proba(X_test)[:,1]\n",
    "    pred_ada = np.where(pred_ada < 0.1, 0, 1)\n",
    "    \n",
    "    ## Calculate recall score and return\n",
    "    return recall_score(Y_test, pred_ada), accuracy_score(Y_test, pred_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d2ac3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to get recall from AdaBoost model with SVC\n",
    "def get_scores_grad(X_train, X_test, Y_train, Y_test):\n",
    "    ## Adaboost model with Support Vector Machine leaners\n",
    "    md_grad = GradientBoostingClassifier(max_depth = 3, n_estimators = 500, learning_rate = 0.01).fit(X_train, Y_train)\n",
    "    \n",
    "    ## Predict and classfify\n",
    "    pred_grad = md_grad.predict_proba(X_test)[:,1]\n",
    "    pred_grad = np.where(pred_grad < 0.1, 0, 1)\n",
    "    \n",
    "    ## Calculate recall score and return\n",
    "    return recall_score(Y_test, pred_grad), accuracy_score(Y_test, pred_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e42193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Average recall score:   0.8579464285714287\n",
      "Average accuracy score: 0.4481830601092897\n",
      "AdaBoost\n",
      "Average recall score:   0.9914285714285715\n",
      "Average accuracy score: 0.15849726775956283\n",
      "Gradient Boosting\n",
      "Average recall score:   0.8104464285714286\n",
      "Average accuracy score: 0.5075683060109291\n"
     ]
    }
   ],
   "source": [
    "## 6.b\n",
    "## list of scores\n",
    "rf_recall_scores = list()\n",
    "rf_accuracy_scores = list()\n",
    "ada_recall_scores = list()\n",
    "ada_accuracy_scores = list()\n",
    "grad_recall_scores = list()\n",
    "grad_accuracy_scores = list()\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    ## Splitting the data\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "    \n",
    "    ## get and store new scores to lists\n",
    "    rf_recall, rf_accuracy = get_scores_rf(X_train, X_test, Y_train, Y_test)\n",
    "    rf_recall_scores.append(rf_recall)\n",
    "    rf_accuracy_scores.append(rf_accuracy)\n",
    "    \n",
    "    ada_recall, ada_accuracy = get_scores_ada(X_train, X_test, Y_train, Y_test)\n",
    "    ada_recall_scores.append(ada_recall)\n",
    "    ada_accuracy_scores.append(ada_accuracy)\n",
    "    \n",
    "    grad_recall, grad_accuracy = get_scores_grad(X_train, X_test, Y_train, Y_test)\n",
    "    grad_recall_scores.append(grad_recall)\n",
    "    grad_accuracy_scores.append(grad_accuracy)    \n",
    "    \n",
    "## print the average recall scores\n",
    "print('Random Forest')\n",
    "print('Average recall score:  ', np.mean(rf_recall_scores))\n",
    "print('Average accuracy score:', np.mean(rf_accuracy_scores))\n",
    "print('AdaBoost')\n",
    "print('Average recall score:  ', np.mean(ada_recall_scores))\n",
    "print('Average accuracy score:', np.mean(ada_accuracy_scores))\n",
    "print('Gradient Boosting')\n",
    "print('Average recall score:  ', np.mean(grad_recall_scores))\n",
    "print('Average accuracy score:', np.mean(grad_accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f68ce9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I would use Gradient Boosting to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c7a7cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "Train dataset\n",
      "Average recall score:   0.8629213483146069\n",
      "Average accuracy score: 0.5241108071135431\n",
      "Test dataset\n",
      "Average recall score:   0.8214285714285714\n",
      "Average accuracy score: 0.5099726775956284\n"
     ]
    }
   ],
   "source": [
    "## 6.c\n",
    "gradient_recall_scores_train = list()\n",
    "gradient_accuracy_scores_train = list()\n",
    "gradient_recall_scores_test = list()\n",
    "gradient_accuracy_scores_test = list()\n",
    "\n",
    "for i in range(10):\n",
    "    ## Splitting the data\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "\n",
    "    md_gradient = GradientBoostingClassifier(max_depth = 3, n_estimators = 500, learning_rate = 0.01).fit(X_train, Y_train)\n",
    "\n",
    "    ## Predict and classfify train dataset\n",
    "    pred_train_gradient = md_gradient.predict_proba(X_train)[:,1]\n",
    "    pred_train_gradient = np.where(pred_train_gradient < 0.1, 0, 1)\n",
    "\n",
    "    ## Predict and classfify test dataset\n",
    "    pred_test_gradient = md_gradient.predict_proba(X_test)[:,1]\n",
    "    pred_test_gradient = np.where(pred_test_gradient < 0.1, 0, 1)\n",
    "\n",
    "    ## Calculate scores\n",
    "    gradient_recall_scores_train.append(recall_score(Y_train, pred_train_gradient))\n",
    "    gradient_accuracy_scores_train.append(accuracy_score(Y_train, pred_train_gradient))\n",
    "    gradient_recall_scores_test.append(recall_score(Y_test, pred_test_gradient))\n",
    "    gradient_accuracy_scores_test.append(accuracy_score(Y_test, pred_test_gradient))\n",
    "\n",
    "print('Gradient Boosting')\n",
    "print('Train dataset')\n",
    "print('Average recall score:  ', np.mean(gradient_recall_scores_train))\n",
    "print('Average accuracy score:', np.mean(gradient_accuracy_scores_train))\n",
    "print('Test dataset')\n",
    "print('Average recall score:  ', np.mean(gradient_recall_scores_test))\n",
    "print('Average accuracy score:', np.mean(gradient_accuracy_scores_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293db052",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The recall and accuracy of train and test are similar, so generalization is good.\n",
    "## The problem is train accuracy is low, the model seems underfit the dataset.\n",
    "## I would increase the number of learners and adjust learning rate accordingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
