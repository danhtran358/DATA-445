{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "204eddc9",
   "metadata": {},
   "source": [
    "## This final notebook will run best models of Logistic Regression, SVC, and Ensembles on same dataset to compare\n",
    "## Dataset: cleaned without missing values from all 8 features (392 observations)\n",
    "## Columns: 3 cases (all 8 features, 6 features LASSO, 5 features importances)\n",
    "## cut off values: 0.3, 0.35, 0.4, 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19f368ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              1       89             66             23       94  28.1   \n",
       "1              0      137             40             35      168  43.1   \n",
       "2              3       78             50             32       88  31.0   \n",
       "3              2      197             70             45      543  30.5   \n",
       "4              1      189             60             23      846  30.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "387            0      181             88             44      510  43.3   \n",
       "388            1      128             88             39      110  36.5   \n",
       "389            2       88             58             26       16  28.4   \n",
       "390           10      101             76             48      180  32.9   \n",
       "391            5      121             72             23      112  26.2   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.167   21        0  \n",
       "1                       2.288   33        1  \n",
       "2                       0.248   26        1  \n",
       "3                       0.158   53        1  \n",
       "4                       0.398   59        1  \n",
       "..                        ...  ...      ...  \n",
       "387                     0.222   26        1  \n",
       "388                     1.057   37        1  \n",
       "389                     0.766   22        0  \n",
       "390                     0.171   63        0  \n",
       "391                     0.245   30        0  \n",
       "\n",
       "[392 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import packages and modules\n",
    "import boto3, botocore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from itertools import product\n",
    "\n",
    "## fetch file content from s3\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('danhtran358-data-445-bucket')\n",
    "\n",
    "bucket_object = bucket.Object('project_cleaned_data.csv')\n",
    "## read file content to data-frame\n",
    "diabetes_cleaned = pd.read_csv(bucket_object.get().get('Body'))\n",
    "diabetes_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e2fcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f8753c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to write write data_frame to csv file object in S3 bucket\n",
    "def write_data_to_s3(file_name, data_frame):\n",
    "    ## file object in s3 bucket\n",
    "    data_file = bucket.Object(file_name)\n",
    "    \n",
    "    ## add content from the lists of recall scores\n",
    "    content = data_frame.to_csv(index=False)\n",
    "\n",
    "    ## store as new csv file\n",
    "    data_file.put(Body = content)\n",
    "    \n",
    "\n",
    "## function to read Random Forest data stored in s3 csv to dataframe\n",
    "def read_rf_data(file_name):\n",
    "    try:\n",
    "        ## file object in s3 bucket\n",
    "        rf_data_file = bucket.Object(file_name)\n",
    "        \n",
    "        rf_data_file.load()\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            ## file does not exist yet, create new file\n",
    "            results = expand_grid(rf_dictionary)\n",
    "            \n",
    "            ## create columns for all types of cut-off values and scores\n",
    "            for i in range(len(cut_off)):\n",
    "                for j in range(len(score_to_evaluate)):\n",
    "                    col = str(cut_off[i]) + '_' + score_to_evaluate[j]\n",
    "                    results[col] = 0.0\n",
    "                    \n",
    "            write_data_to_s3(file_name, results)\n",
    "            \n",
    "            ## return the dataframe from newly created file\n",
    "            return pd.read_csv(rf_data_file.get().get('Body'))\n",
    "    else:\n",
    "        ## return the dataframe already stored\n",
    "        return pd.read_csv(rf_data_file.get().get('Body'))\n",
    "\n",
    "    \n",
    "## function to read AdaBoosting/Gradient Boosting data stored in s3 csv to dataframe\n",
    "def read_ada_data(file_name):\n",
    "    try:\n",
    "        ## file object in s3 bucket\n",
    "        boosting_data_file = bucket.Object(file_name)\n",
    "        \n",
    "        boosting_data_file.load()\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            ## file does not exist yet, create new file\n",
    "            results = expand_grid(ada_dictionary)\n",
    "            \n",
    "            ## create columns for all types of cut-off values and scores\n",
    "            for i in range(len(cut_off)):\n",
    "                for j in range(len(score_to_evaluate)):\n",
    "                    col = str(cut_off[i]) + '_' + score_to_evaluate[j]\n",
    "                    results[col] = 0.0\n",
    "                    \n",
    "            write_data_to_s3(file_name, results)\n",
    "            \n",
    "            ## return the dataframe from newly created file\n",
    "            return pd.read_csv(boosting_data_file.get().get('Body'))\n",
    "    else:\n",
    "        ## return the dataframe already stored\n",
    "        return pd.read_csv(boosting_data_file.get().get('Body'))\n",
    "\n",
    "    \n",
    "## function to read AdaBoosting/Gradient Boosting data stored in s3 csv to dataframe\n",
    "def read_grad_data(file_name):\n",
    "    try:\n",
    "        ## file object in s3 bucket\n",
    "        boosting_data_file = bucket.Object(file_name)\n",
    "        \n",
    "        boosting_data_file.load()\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            ## file does not exist yet, create new file\n",
    "            results = expand_grid(grad_dictionary)\n",
    "            \n",
    "            ## create columns for all types of cut-off values and scores\n",
    "            for i in range(len(cut_off)):\n",
    "                for j in range(len(score_to_evaluate)):\n",
    "                    col = str(cut_off[i]) + '_' + score_to_evaluate[j]\n",
    "                    results[col] = 0.0\n",
    "                    \n",
    "            write_data_to_s3(file_name, results)\n",
    "            \n",
    "            ## return the dataframe from newly created file\n",
    "            return pd.read_csv(boosting_data_file.get().get('Body'))\n",
    "    else:\n",
    "        ## return the dataframe already stored\n",
    "        return pd.read_csv(boosting_data_file.get().get('Body'))\n",
    "    \n",
    "\n",
    "## function to read Random Forest data stored in s3 csv to dataframe\n",
    "def read_data_from_s3(file_name, X = None):\n",
    "    try:\n",
    "        ## file object in s3 bucket\n",
    "        data_file = bucket.Object(file_name)\n",
    "        \n",
    "        data_file.load()\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            ## file does not exist yet, create new file\n",
    "            if X is None:\n",
    "                results = expand_grid(basic_dictionary)\n",
    "\n",
    "                ## create columns for all types of cut-off values and scores\n",
    "                for i in range(len(cut_off)):\n",
    "                    for j in range(len(score_to_evaluate)):\n",
    "                        col = str(cut_off[i]) + '_' + score_to_evaluate[j]\n",
    "                        results[col] = 0.0\n",
    "            \n",
    "            else:\n",
    "                ## empty dataframe with first row has 0 for total loops\n",
    "                empty_list = list()\n",
    "                results = pd.DataFrame(empty_list, columns = X.columns)\n",
    "                results.at[0, 'total_loops'] = 0\n",
    "                   \n",
    "            ## write brand new and empty file to s3\n",
    "            write_data_to_s3(file_name, results)\n",
    "            \n",
    "            ## return the dataframe from newly created file\n",
    "            return pd.read_csv(data_file.get().get('Body'))\n",
    "    else:\n",
    "        ## return the dataframe already stored\n",
    "        return pd.read_csv(data_file.get().get('Body'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ea19324",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use dataframes to store parameters to build models and store total scores\n",
    "def expand_grid(dictionary):\n",
    "    return pd.DataFrame([row for row in product(*dictionary.values())], columns = dictionary.keys())\n",
    "\n",
    "basic_dictionary = {'input_layer': [5, 6, 8], 'total_loops' : [0]}\n",
    "\n",
    "rf_dictionary = {'input_layer': [5, 6, 8], 'total_loops' : [0], 'n_tree': [500], 'depth': [3]}\n",
    "\n",
    "ada_dictionary = {'input_layer': [5, 6, 8], 'total_loops' : [0], 'n_tree': [500], 'depth': [3], 'learning_rate': [0.001]}\n",
    "\n",
    "grad_dictionary = {'input_layer': [5, 6, 8], 'total_loops' : [0], 'n_tree': [1000, 1500], 'depth': [3], 'learning_rate': [0.001]}\n",
    "\n",
    "## lists of cut-off values and types of score to evaluate models\n",
    "cut_off = [0.3, 0.35, 0.4, 0.45]\n",
    "score_to_evaluate = ['precision', 'recall', 'f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7595f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "## update the scores in result dataset after each ensemble model is built\n",
    "def update_ensemble_result_scores(pred, Y_test, results, combo_number):\n",
    "    \n",
    "    for cut_off_id in range(len(cut_off)):\n",
    "        \n",
    "        ## classify labels\n",
    "        current_cut_off = cut_off[cut_off_id]\n",
    "        pred_labels = np.where(pred < current_cut_off, 0, 1)\n",
    "        \n",
    "        for score_id in range(len(score_to_evaluate)):\n",
    "            \n",
    "            ## updated the appropriate score\n",
    "            current_score = score_to_evaluate[score_id]\n",
    "            score_column = str(current_cut_off) + '_' + current_score\n",
    "            if current_score == 'precision':\n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + precision_score(Y_test, pred_labels, zero_division = 0)\n",
    "            \n",
    "            elif current_score == 'recall':\n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + recall_score(Y_test, pred_labels)\n",
    "                \n",
    "            elif current_score == 'f1': \n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + f1_score(Y_test, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bdc51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## update the scores in result dataset after each model is built\n",
    "def update_svc_linear_result_scores(X_train, X_test, Y_train, Y_test, results, combo_number):\n",
    "    \n",
    "    ## Building the svc with kernel = 'linear'\n",
    "    md_svc_linear = SVC(kernel = 'linear', probability = True).fit(X_train, Y_train)\n",
    "\n",
    "    ## Making predictions on the test dataset\n",
    "    pred = md_svc_linear.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    for cut_off_id in range(len(cut_off)):\n",
    "        \n",
    "        ## classify labels\n",
    "        current_cut_off = cut_off[cut_off_id]\n",
    "        pred_labels = np.where(pred < current_cut_off, 0, 1)\n",
    "        \n",
    "        for score_id in range(len(score_to_evaluate)):\n",
    "            \n",
    "            ## updated the appropriate score\n",
    "            current_score = score_to_evaluate[score_id]\n",
    "            score_column = str(current_cut_off) + '_' + current_score\n",
    "            \n",
    "            if current_score == 'precision':\n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + precision_score(Y_test, pred_labels, zero_division = 0)\n",
    "            \n",
    "            elif current_score == 'recall':\n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + recall_score(Y_test, pred_labels)\n",
    "                \n",
    "            elif current_score == 'f1': \n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + f1_score(Y_test, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1683ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## update the scores in result dataset after each model is built\n",
    "def update_logistic_result_scores(X_train, X_test, Y_train, Y_test, results, combo_number):\n",
    "\n",
    "    ## build logistic models\n",
    "    logit_md = LogisticRegression().fit(X_train, Y_train)\n",
    "\n",
    "    ## predict the likelihood\n",
    "    pred = logit_md.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    for cut_off_id in range(len(cut_off)):\n",
    "        \n",
    "        ## classify labels\n",
    "        current_cut_off = cut_off[cut_off_id]\n",
    "        pred_labels = np.where(pred < current_cut_off, 0, 1)\n",
    "        \n",
    "        for score_id in range(len(score_to_evaluate)):\n",
    "            \n",
    "            ## updated the appropriate score\n",
    "            current_score = score_to_evaluate[score_id]\n",
    "            score_column = str(current_cut_off) + '_' + current_score\n",
    "            \n",
    "            if current_score == 'precision':\n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + precision_score(Y_test, pred_labels, zero_division = 0)\n",
    "            \n",
    "            elif current_score == 'recall':\n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + recall_score(Y_test, pred_labels)\n",
    "                \n",
    "            elif current_score == 'f1': \n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + f1_score(Y_test, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11865553",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining input and target variables\n",
    "X = diabetes_cleaned.drop(columns = ['Outcome'])\n",
    "Y = diabetes_cleaned['Outcome']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "## read data stored in s3 file\n",
    "rf_data_file_name = 'project_final_rf_data.csv'\n",
    "rf_results = read_rf_data(rf_data_file_name)\n",
    "ada_data_file_name = 'project_final_ada_data.csv'\n",
    "ada_results = read_ada_data(ada_data_file_name)\n",
    "grad_data_file_name = 'project_final_grad_data.csv'\n",
    "grad_results = read_grad_data(grad_data_file_name)\n",
    "svc_data_file_name = 'project_final_svc_result.csv'\n",
    "svc_results = read_data_from_s3(svc_data_file_name)\n",
    "logistic_data_file_name = 'project_final_logistic_result.csv'\n",
    "logistic_results = read_data_from_s3(logistic_data_file_name)\n",
    "\n",
    "## total_loops column keeps the number of loops already done, we only loop the rest until 100 times done\n",
    "for loop_number in range(svc_results.at[0, 'total_loops'], 100):\n",
    "    \n",
    "    ## Dataset 1\n",
    "    X_train_8_features, X_test_8_features, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "    \n",
    "    ## Dataset 2 inputs\n",
    "    X_train_6_features = X_train_8_features.drop(columns = ['BloodPressure', 'Insulin'], axis = 1)\n",
    "    X_test_6_features = X_test_8_features.drop(columns = ['BloodPressure', 'Insulin'], axis = 1)\n",
    "    \n",
    "    ## Dataset 4 inputs\n",
    "    X_train_5_features = X_train_8_features.drop(columns = ['Pregnancies', 'BloodPressure', 'SkinThickness'], axis = 1)\n",
    "    X_test_5_features = X_test_8_features.drop(columns = ['Pregnancies', 'BloodPressure', 'SkinThickness'], axis = 1)\n",
    "                \n",
    "    ## scale input variables to 0-1 scale\n",
    "    X_train_8_features = scaler.fit_transform(X_train_8_features)\n",
    "    X_test_8_features = scaler.fit_transform(X_test_8_features)\n",
    "    X_train_6_features = scaler.fit_transform(X_train_6_features)\n",
    "    X_test_6_features = scaler.fit_transform(X_test_6_features)\n",
    "    X_train_5_features = scaler.fit_transform(X_train_5_features)\n",
    "    X_test_5_features = scaler.fit_transform(X_test_5_features)\n",
    "    \n",
    "    ## Build random forest for each parameter combination and store scores\n",
    "    for combo_number in range(rf_results.shape[0]):\n",
    "        parameters = rf_results.loc[combo_number]\n",
    "            \n",
    "        if parameters['input_layer'] == 5:\n",
    "            X_train = X_train_5_features\n",
    "            X_test = X_test_5_features\n",
    "        elif parameters['input_layer'] == 6:\n",
    "            X_train = X_train_6_features\n",
    "            X_test = X_test_6_features\n",
    "        elif parameters['input_layer'] == 8:\n",
    "            X_train = X_train_8_features\n",
    "            X_test = X_test_8_features\n",
    "        \n",
    "        ## Building model, predicting results, and update scores\n",
    "        md_rf = RandomForestClassifier(max_depth = parameters['depth'],\n",
    "                                       n_estimators = int(parameters['n_tree'])).fit(X_train, Y_train)\n",
    "        pred = md_rf.predict_proba(X_test)[:, 1]\n",
    "        update_ensemble_result_scores(pred, Y_test, rf_results, combo_number)\n",
    "    \n",
    "    ## Build AdaBoost model for each parameter combination and store scores\n",
    "    for combo_number in range(ada_results.shape[0]):\n",
    "        parameters = ada_results.loc[combo_number]\n",
    "            \n",
    "        if parameters['input_layer'] == 5:\n",
    "            X_train = X_train_5_features\n",
    "            X_test = X_test_5_features\n",
    "        elif parameters['input_layer'] == 6:\n",
    "            X_train = X_train_6_features\n",
    "            X_test = X_test_6_features\n",
    "        elif parameters['input_layer'] == 8:\n",
    "            X_train = X_train_8_features\n",
    "            X_test = X_test_8_features\n",
    "        \n",
    "        ## Building model, predicting results, and update scores\n",
    "        md_ada = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = parameters['depth']),\n",
    "                                    n_estimators = int(parameters['n_tree']),\n",
    "                                    learning_rate = parameters['learning_rate']).fit(X_train, Y_train)\n",
    "        pred = md_ada.predict_proba(X_test)[:, 1]\n",
    "        update_ensemble_result_scores(pred, Y_test, ada_results, combo_number)\n",
    "    \n",
    "    ## Build Gradient Boosting model for each parameter combination and store scores\n",
    "    for combo_number in range(grad_results.shape[0]):\n",
    "        parameters = grad_results.loc[combo_number]\n",
    "            \n",
    "        if parameters['input_layer'] == 5:\n",
    "            X_train = X_train_5_features\n",
    "            X_test = X_test_5_features\n",
    "        elif parameters['input_layer'] == 6:\n",
    "            X_train = X_train_6_features\n",
    "            X_test = X_test_6_features\n",
    "        elif parameters['input_layer'] == 8:\n",
    "            X_train = X_train_8_features\n",
    "            X_test = X_test_8_features\n",
    "        \n",
    "        ## Building model, predicting results, and update scores\n",
    "        md_grad = GradientBoostingClassifier(max_depth = parameters['depth'],\n",
    "                                             n_estimators = int(parameters['n_tree']),\n",
    "                                             learning_rate = parameters['learning_rate']).fit(X_train, Y_train)\n",
    "        pred = md_grad.predict_proba(X_test)[:, 1]\n",
    "        update_ensemble_result_scores(pred, Y_test, grad_results, combo_number)\n",
    "    \n",
    "    ## Build SVC model linear kernel for each parameter combination and store scores\n",
    "    for combo_number in range(svc_results.shape[0]):\n",
    "        parameters = svc_results.loc[combo_number]\n",
    "            \n",
    "        if parameters['input_layer'] == 5:\n",
    "            X_train = X_train_5_features\n",
    "            X_test = X_test_5_features\n",
    "        elif parameters['input_layer'] == 6:\n",
    "            X_train = X_train_6_features\n",
    "            X_test = X_test_6_features\n",
    "        elif parameters['input_layer'] == 8:\n",
    "            X_train = X_train_8_features\n",
    "            X_test = X_test_8_features\n",
    "        \n",
    "        update_svc_linear_result_scores(X_train, X_test, Y_train, Y_test, svc_results, combo_number)\n",
    "    \n",
    "    ## Build Logistic model for each parameter combination and store scores\n",
    "    for combo_number in range(logistic_results.shape[0]):\n",
    "        parameters = svc_results.loc[combo_number]\n",
    "            \n",
    "        if parameters['input_layer'] == 5:\n",
    "            X_train = X_train_5_features\n",
    "            X_test = X_test_5_features\n",
    "        elif parameters['input_layer'] == 6:\n",
    "            X_train = X_train_6_features\n",
    "            X_test = X_test_6_features\n",
    "        elif parameters['input_layer'] == 8:\n",
    "            X_train = X_train_8_features\n",
    "            X_test = X_test_8_features\n",
    "        \n",
    "        update_logistic_result_scores(X_train, X_test, Y_train, Y_test, logistic_results, combo_number)\n",
    "        \n",
    "    rf_results['total_loops'] = loop_number + 1\n",
    "    ada_results['total_loops'] = loop_number + 1\n",
    "    grad_results['total_loops'] = loop_number + 1\n",
    "    svc_results['total_loops'] = loop_number + 1\n",
    "    logistic_results['total_loops'] = loop_number + 1\n",
    "    ## Writing data to s3\n",
    "    write_data_to_s3(rf_data_file_name, rf_results)\n",
    "    write_data_to_s3(ada_data_file_name, ada_results)\n",
    "    write_data_to_s3(grad_data_file_name, grad_results)\n",
    "    write_data_to_s3(svc_data_file_name, svc_results)\n",
    "    write_data_to_s3(logistic_data_file_name, logistic_results)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28dfc9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_layer</th>\n",
       "      <th>0.3_precision</th>\n",
       "      <th>0.3_recall</th>\n",
       "      <th>0.3_f1</th>\n",
       "      <th>0.35_precision</th>\n",
       "      <th>0.35_recall</th>\n",
       "      <th>0.35_f1</th>\n",
       "      <th>0.4_precision</th>\n",
       "      <th>0.4_recall</th>\n",
       "      <th>0.4_f1</th>\n",
       "      <th>0.45_precision</th>\n",
       "      <th>0.45_recall</th>\n",
       "      <th>0.45_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.551962</td>\n",
       "      <td>0.882308</td>\n",
       "      <td>0.674351</td>\n",
       "      <td>0.585533</td>\n",
       "      <td>0.834231</td>\n",
       "      <td>0.682532</td>\n",
       "      <td>0.625248</td>\n",
       "      <td>0.775769</td>\n",
       "      <td>0.684227</td>\n",
       "      <td>0.667385</td>\n",
       "      <td>0.702308</td>\n",
       "      <td>0.673952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.536276</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.660811</td>\n",
       "      <td>0.578060</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.666925</td>\n",
       "      <td>0.617009</td>\n",
       "      <td>0.718846</td>\n",
       "      <td>0.656621</td>\n",
       "      <td>0.674562</td>\n",
       "      <td>0.642308</td>\n",
       "      <td>0.648847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.534251</td>\n",
       "      <td>0.899615</td>\n",
       "      <td>0.666418</td>\n",
       "      <td>0.579299</td>\n",
       "      <td>0.847692</td>\n",
       "      <td>0.683827</td>\n",
       "      <td>0.617430</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.680490</td>\n",
       "      <td>0.661862</td>\n",
       "      <td>0.686923</td>\n",
       "      <td>0.665886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_layer  0.3_precision  0.3_recall    0.3_f1  0.35_precision  \\\n",
       "0         0.05       0.551962    0.882308  0.674351        0.585533   \n",
       "1         0.06       0.536276    0.875000  0.660811        0.578060   \n",
       "2         0.08       0.534251    0.899615  0.666418        0.579299   \n",
       "\n",
       "   0.35_recall   0.35_f1  0.4_precision  0.4_recall    0.4_f1  0.45_precision  \\\n",
       "0     0.834231  0.682532       0.625248    0.775769  0.684227        0.667385   \n",
       "1     0.803846  0.666925       0.617009    0.718846  0.656621        0.674562   \n",
       "2     0.847692  0.683827       0.617430    0.773077  0.680490        0.661862   \n",
       "\n",
       "   0.45_recall   0.45_f1  \n",
       "0     0.702308  0.673952  \n",
       "1     0.642308  0.648847  \n",
       "2     0.686923  0.665886  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_results.drop(columns = ['total_loops', 'n_tree', 'depth']) / rf_results.at[0, 'total_loops']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe17c579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_layer</th>\n",
       "      <th>0.3_precision</th>\n",
       "      <th>0.3_recall</th>\n",
       "      <th>0.3_f1</th>\n",
       "      <th>0.35_precision</th>\n",
       "      <th>0.35_recall</th>\n",
       "      <th>0.35_f1</th>\n",
       "      <th>0.4_precision</th>\n",
       "      <th>0.4_recall</th>\n",
       "      <th>0.4_f1</th>\n",
       "      <th>0.45_precision</th>\n",
       "      <th>0.45_recall</th>\n",
       "      <th>0.45_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.563520</td>\n",
       "      <td>0.793077</td>\n",
       "      <td>0.651727</td>\n",
       "      <td>0.581741</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.653210</td>\n",
       "      <td>0.596970</td>\n",
       "      <td>0.738077</td>\n",
       "      <td>0.651607</td>\n",
       "      <td>0.611314</td>\n",
       "      <td>0.698846</td>\n",
       "      <td>0.641427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.567912</td>\n",
       "      <td>0.771538</td>\n",
       "      <td>0.647054</td>\n",
       "      <td>0.587797</td>\n",
       "      <td>0.736538</td>\n",
       "      <td>0.645981</td>\n",
       "      <td>0.614159</td>\n",
       "      <td>0.708462</td>\n",
       "      <td>0.649248</td>\n",
       "      <td>0.629946</td>\n",
       "      <td>0.666538</td>\n",
       "      <td>0.638531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.558340</td>\n",
       "      <td>0.781154</td>\n",
       "      <td>0.645145</td>\n",
       "      <td>0.579380</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.648847</td>\n",
       "      <td>0.597855</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.647411</td>\n",
       "      <td>0.609192</td>\n",
       "      <td>0.690769</td>\n",
       "      <td>0.639121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_layer  0.3_precision  0.3_recall    0.3_f1  0.35_precision  \\\n",
       "0         0.05       0.563520    0.793077  0.651727        0.581741   \n",
       "1         0.06       0.567912    0.771538  0.647054        0.587797   \n",
       "2         0.08       0.558340    0.781154  0.645145        0.579380   \n",
       "\n",
       "   0.35_recall   0.35_f1  0.4_precision  0.4_recall    0.4_f1  0.45_precision  \\\n",
       "0     0.765000  0.653210       0.596970    0.738077  0.651607        0.611314   \n",
       "1     0.736538  0.645981       0.614159    0.708462  0.649248        0.629946   \n",
       "2     0.753846  0.648847       0.597855    0.723077  0.647411        0.609192   \n",
       "\n",
       "   0.45_recall   0.45_f1  \n",
       "0     0.698846  0.641427  \n",
       "1     0.666538  0.638531  \n",
       "2     0.690769  0.639121  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_results.drop(columns = ['total_loops', 'n_tree', 'depth', 'learning_rate']) / ada_results.at[0, 'total_loops']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2ff15ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_layer</th>\n",
       "      <th>n_tree</th>\n",
       "      <th>0.3_precision</th>\n",
       "      <th>0.3_recall</th>\n",
       "      <th>0.3_f1</th>\n",
       "      <th>0.35_precision</th>\n",
       "      <th>0.35_recall</th>\n",
       "      <th>0.35_f1</th>\n",
       "      <th>0.4_precision</th>\n",
       "      <th>0.4_recall</th>\n",
       "      <th>0.4_f1</th>\n",
       "      <th>0.45_precision</th>\n",
       "      <th>0.45_recall</th>\n",
       "      <th>0.45_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.546654</td>\n",
       "      <td>0.836154</td>\n",
       "      <td>0.654574</td>\n",
       "      <td>0.574260</td>\n",
       "      <td>0.786154</td>\n",
       "      <td>0.655423</td>\n",
       "      <td>0.605411</td>\n",
       "      <td>0.728462</td>\n",
       "      <td>0.650858</td>\n",
       "      <td>0.639482</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.631907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.552279</td>\n",
       "      <td>0.837308</td>\n",
       "      <td>0.658191</td>\n",
       "      <td>0.577964</td>\n",
       "      <td>0.799231</td>\n",
       "      <td>0.662292</td>\n",
       "      <td>0.604508</td>\n",
       "      <td>0.743462</td>\n",
       "      <td>0.656150</td>\n",
       "      <td>0.634170</td>\n",
       "      <td>0.680385</td>\n",
       "      <td>0.644289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.542847</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.642539</td>\n",
       "      <td>0.583173</td>\n",
       "      <td>0.749231</td>\n",
       "      <td>0.647340</td>\n",
       "      <td>0.611183</td>\n",
       "      <td>0.672308</td>\n",
       "      <td>0.631239</td>\n",
       "      <td>0.644667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.611922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.547419</td>\n",
       "      <td>0.808077</td>\n",
       "      <td>0.645635</td>\n",
       "      <td>0.584287</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.652661</td>\n",
       "      <td>0.609305</td>\n",
       "      <td>0.701538</td>\n",
       "      <td>0.643597</td>\n",
       "      <td>0.638915</td>\n",
       "      <td>0.629615</td>\n",
       "      <td>0.625036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.08</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.540913</td>\n",
       "      <td>0.829231</td>\n",
       "      <td>0.649120</td>\n",
       "      <td>0.575755</td>\n",
       "      <td>0.781154</td>\n",
       "      <td>0.655551</td>\n",
       "      <td>0.602948</td>\n",
       "      <td>0.719615</td>\n",
       "      <td>0.646483</td>\n",
       "      <td>0.638898</td>\n",
       "      <td>0.639231</td>\n",
       "      <td>0.628492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.08</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.546402</td>\n",
       "      <td>0.833077</td>\n",
       "      <td>0.654176</td>\n",
       "      <td>0.576617</td>\n",
       "      <td>0.792692</td>\n",
       "      <td>0.660384</td>\n",
       "      <td>0.602490</td>\n",
       "      <td>0.741154</td>\n",
       "      <td>0.655296</td>\n",
       "      <td>0.629999</td>\n",
       "      <td>0.671538</td>\n",
       "      <td>0.640154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_layer  n_tree  0.3_precision  0.3_recall    0.3_f1  0.35_precision  \\\n",
       "0         0.05    10.0       0.546654    0.836154  0.654574        0.574260   \n",
       "1         0.05    15.0       0.552279    0.837308  0.658191        0.577964   \n",
       "2         0.06    10.0       0.542847    0.807692  0.642539        0.583173   \n",
       "3         0.06    15.0       0.547419    0.808077  0.645635        0.584287   \n",
       "4         0.08    10.0       0.540913    0.829231  0.649120        0.575755   \n",
       "5         0.08    15.0       0.546402    0.833077  0.654176        0.576617   \n",
       "\n",
       "   0.35_recall   0.35_f1  0.4_precision  0.4_recall    0.4_f1  0.45_precision  \\\n",
       "0     0.786154  0.655423       0.605411    0.728462  0.650858        0.639482   \n",
       "1     0.799231  0.662292       0.604508    0.743462  0.656150        0.634170   \n",
       "2     0.749231  0.647340       0.611183    0.672308  0.631239        0.644667   \n",
       "3     0.760000  0.652661       0.609305    0.701538  0.643597        0.638915   \n",
       "4     0.781154  0.655551       0.602948    0.719615  0.646483        0.638898   \n",
       "5     0.792692  0.660384       0.602490    0.741154  0.655296        0.629999   \n",
       "\n",
       "   0.45_recall   0.45_f1  \n",
       "0     0.650000  0.631907  \n",
       "1     0.680385  0.644289  \n",
       "2     0.600000  0.611922  \n",
       "3     0.629615  0.625036  \n",
       "4     0.639231  0.628492  \n",
       "5     0.671538  0.640154  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_results.drop(columns = ['total_loops', 'depth', 'learning_rate']) / grad_results.at[0, 'total_loops']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e78e023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_layer</th>\n",
       "      <th>0.3_precision</th>\n",
       "      <th>0.3_recall</th>\n",
       "      <th>0.3_f1</th>\n",
       "      <th>0.35_precision</th>\n",
       "      <th>0.35_recall</th>\n",
       "      <th>0.35_f1</th>\n",
       "      <th>0.4_precision</th>\n",
       "      <th>0.4_recall</th>\n",
       "      <th>0.4_f1</th>\n",
       "      <th>0.45_precision</th>\n",
       "      <th>0.45_recall</th>\n",
       "      <th>0.45_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.583477</td>\n",
       "      <td>0.831538</td>\n",
       "      <td>0.679307</td>\n",
       "      <td>0.617385</td>\n",
       "      <td>0.792692</td>\n",
       "      <td>0.686335</td>\n",
       "      <td>0.642519</td>\n",
       "      <td>0.741923</td>\n",
       "      <td>0.680002</td>\n",
       "      <td>0.668916</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.674752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.583917</td>\n",
       "      <td>0.831538</td>\n",
       "      <td>0.679984</td>\n",
       "      <td>0.609948</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.679540</td>\n",
       "      <td>0.638038</td>\n",
       "      <td>0.734231</td>\n",
       "      <td>0.674693</td>\n",
       "      <td>0.658899</td>\n",
       "      <td>0.686923</td>\n",
       "      <td>0.663253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.577355</td>\n",
       "      <td>0.829231</td>\n",
       "      <td>0.674927</td>\n",
       "      <td>0.606397</td>\n",
       "      <td>0.783077</td>\n",
       "      <td>0.676292</td>\n",
       "      <td>0.631650</td>\n",
       "      <td>0.736538</td>\n",
       "      <td>0.671987</td>\n",
       "      <td>0.652619</td>\n",
       "      <td>0.685769</td>\n",
       "      <td>0.659336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_layer  0.3_precision  0.3_recall    0.3_f1  0.35_precision  \\\n",
       "0         0.05       0.583477    0.831538  0.679307        0.617385   \n",
       "1         0.06       0.583917    0.831538  0.679984        0.609948   \n",
       "2         0.08       0.577355    0.829231  0.674927        0.606397   \n",
       "\n",
       "   0.35_recall   0.35_f1  0.4_precision  0.4_recall    0.4_f1  0.45_precision  \\\n",
       "0     0.792692  0.686335       0.642519    0.741923  0.680002        0.668916   \n",
       "1     0.785000  0.679540       0.638038    0.734231  0.674693        0.658899   \n",
       "2     0.783077  0.676292       0.631650    0.736538  0.671987        0.652619   \n",
       "\n",
       "   0.45_recall   0.45_f1  \n",
       "0     0.700000  0.674752  \n",
       "1     0.686923  0.663253  \n",
       "2     0.685769  0.659336  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_results.drop(columns = ['total_loops']) / svc_results.at[0, 'total_loops']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53ebb987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_layer</th>\n",
       "      <th>0.3_precision</th>\n",
       "      <th>0.3_recall</th>\n",
       "      <th>0.3_f1</th>\n",
       "      <th>0.35_precision</th>\n",
       "      <th>0.35_recall</th>\n",
       "      <th>0.35_f1</th>\n",
       "      <th>0.4_precision</th>\n",
       "      <th>0.4_recall</th>\n",
       "      <th>0.4_f1</th>\n",
       "      <th>0.45_precision</th>\n",
       "      <th>0.45_recall</th>\n",
       "      <th>0.45_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.572066</td>\n",
       "      <td>0.853077</td>\n",
       "      <td>0.678931</td>\n",
       "      <td>0.615346</td>\n",
       "      <td>0.794615</td>\n",
       "      <td>0.686044</td>\n",
       "      <td>0.652609</td>\n",
       "      <td>0.733077</td>\n",
       "      <td>0.681795</td>\n",
       "      <td>0.675995</td>\n",
       "      <td>0.672308</td>\n",
       "      <td>0.663959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.567528</td>\n",
       "      <td>0.853077</td>\n",
       "      <td>0.676444</td>\n",
       "      <td>0.599019</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.673753</td>\n",
       "      <td>0.634217</td>\n",
       "      <td>0.726538</td>\n",
       "      <td>0.669358</td>\n",
       "      <td>0.665669</td>\n",
       "      <td>0.667692</td>\n",
       "      <td>0.657748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.562934</td>\n",
       "      <td>0.850385</td>\n",
       "      <td>0.672439</td>\n",
       "      <td>0.593935</td>\n",
       "      <td>0.793077</td>\n",
       "      <td>0.672636</td>\n",
       "      <td>0.626703</td>\n",
       "      <td>0.726538</td>\n",
       "      <td>0.666165</td>\n",
       "      <td>0.656134</td>\n",
       "      <td>0.668077</td>\n",
       "      <td>0.653799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input_layer  0.3_precision  0.3_recall    0.3_f1  0.35_precision  \\\n",
       "0         0.05       0.572066    0.853077  0.678931        0.615346   \n",
       "1         0.06       0.567528    0.853077  0.676444        0.599019   \n",
       "2         0.08       0.562934    0.850385  0.672439        0.593935   \n",
       "\n",
       "   0.35_recall   0.35_f1  0.4_precision  0.4_recall    0.4_f1  0.45_precision  \\\n",
       "0     0.794615  0.686044       0.652609    0.733077  0.681795        0.675995   \n",
       "1     0.790000  0.673753       0.634217    0.726538  0.669358        0.665669   \n",
       "2     0.793077  0.672636       0.626703    0.726538  0.666165        0.656134   \n",
       "\n",
       "   0.45_recall   0.45_f1  \n",
       "0     0.672308  0.663959  \n",
       "1     0.667692  0.657748  \n",
       "2     0.668077  0.653799  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_results.drop(columns = ['total_loops']) / logistic_results.at[0, 'total_loops']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0d101ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random forest 500 trees depth 5,   cleaned dataset 5 features, cut-off = 0.35,   precision = 0.585533,   recall = 0.834231,   f1 = 0.682532\n",
    "## SVC model linear kernel,           cleaned dataset 5 features, cut-off = 0.35,   precision = 0.617385,   recall = 0.792692,   f1 = 0.686335\n",
    "## Logistic model,                    cleaned dataset 5 features, cut-off = 0.35,   precision = 0.615346,   recall = 0.794615,   f1 = 0.686044\n",
    "\n",
    "## Logistic model looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining input and target variables\n",
    "X = diabetes_cleaned.drop(columns = ['Outcome', 'Pregnancies', 'BloodPressure', 'SkinThickness'])\n",
    "Y = diabetes_cleaned['Outcome']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "cut_off = 0.35\n",
    "    \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "\n",
    "## scale input variables to 0-1 scale\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "## Building random forest and predict\n",
    "md_rf = RandomForestClassifier(max_depth = 5, n_estimators = 500).fit(X_train, Y_train)\n",
    "rf_pred = md_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "## Building the svc with kernel = 'linear' and predict\n",
    "md_svc_linear = SVC(kernel = 'linear', probability = True).fit(X_train, Y_train)\n",
    "svc_pred = md_svc_linear.predict_proba(X_test)[:,1]\n",
    "\n",
    "## build logistic models and predict\n",
    "logit_md = LogisticRegression().fit(X_train, Y_train)\n",
    "logit_pred = logit_md.predict_proba(X_test)[:,1]\n",
    "\n",
    "## Input variables\n",
    "X_rf_stacked = pd.concat([pd.DataFrame(rf_pred),pd.DataFrame(svc_pred),pd.DataFrame(logit_pred)], axis = 1)\n",
    "\n",
    "## Random forest model\n",
    "md_rf_stacked = RandomForestClassifier(max_depth = 3, n_estimators = 500).fit(X_rf_stacked, Y_test)\n",
    "\n",
    "## Extracting ensemble likelihood\n",
    "pred_rf_stacked = md_rf_stacked.predict_proba(X_rf_stacked)[:,1]\n",
    "\n",
    "## Classifying\n",
    "pred_rf_stacked = np.where(pred_rf_stacked < cut_off, 0, 1)\n",
    "\n",
    "print('Precision score:', precision_score(Y_test, pred_rf_stacked))\n",
    "print('Recall score:   ', recall_score(Y_test, pred_rf_stacked))\n",
    "print('F1 score:       ', f1_score(Y_test, pred_rf_stacked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bdce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Score is boosted after stacking\n",
    "## There might be a data leak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b3a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining input and target variables\n",
    "X = diabetes_cleaned.drop(columns = ['Outcome', 'Pregnancies', 'BloodPressure', 'SkinThickness'])\n",
    "Y = diabetes_cleaned['Outcome']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "cut_off = 0.35\n",
    "    \n",
    "## Split data into testing and training datasets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "\n",
    "## Split test datasets in 2, 1 to build stacked model, the other is to validate the model\n",
    "X_test, X_stacked_vaidate, Y_test, Y_stacked_validate = train_test_split(X_test, Y_test, test_size = 0.5, stratify = Y_test)\n",
    "\n",
    "## scale input variables to 0-1 scale\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "## Building random forest and predict\n",
    "md_rf = RandomForestClassifier(max_depth = 5, n_estimators = 500).fit(X_train, Y_train)\n",
    "rf_pred = md_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "## Building the svc with kernel = 'linear' and predict\n",
    "md_svc_linear = SVC(kernel = 'linear', probability = True).fit(X_train, Y_train)\n",
    "svc_pred = md_svc_linear.predict_proba(X_test)[:,1]\n",
    "\n",
    "## build logistic models and predict\n",
    "logit_md = LogisticRegression().fit(X_train, Y_train)\n",
    "logit_pred = logit_md.predict_proba(X_test)[:,1]\n",
    "\n",
    "## Input variables\n",
    "X_rf_stacked = pd.concat([pd.DataFrame(rf_pred),pd.DataFrame(svc_pred),pd.DataFrame(logit_pred)], axis = 1)\n",
    "\n",
    "## Random forest model\n",
    "md_rf_stacked = RandomForestClassifier(max_depth = 3, n_estimators = 500).fit(X_rf_stacked, Y_test)\n",
    "\n",
    "## Validating the stacked model\n",
    "## Predicting on dataset to validate the stacked model\n",
    "rf_pred = md_rf.predict_proba(X_stacked_vaidate)[:, 1]\n",
    "svc_pred = md_svc_linear.predict_proba(X_stacked_vaidate)[:,1]\n",
    "logit_pred = logit_md.predict_proba(X_stacked_vaidate)[:,1]\n",
    "\n",
    "## Input variables\n",
    "X_rf_stacked_validate = pd.concat([pd.DataFrame(rf_pred),pd.DataFrame(svc_pred),pd.DataFrame(logit_pred)], axis = 1)\n",
    "\n",
    "## Extracting ensemble likelihood\n",
    "pred_rf_stacked = md_rf_stacked.predict_proba(X_rf_stacked_validate)[:,1]\n",
    "\n",
    "## Classifying\n",
    "pred_rf_stacked = np.where(pred_rf_stacked < cut_off, 0, 1)\n",
    "\n",
    "print('Precision score:', precision_score(Y_stacked_validate, pred_rf_stacked))\n",
    "print('Recall score:   ', recall_score(Y_stacked_validate, pred_rf_stacked))\n",
    "print('F1 score:       ', f1_score(Y_stacked_validate, pred_rf_stacked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9b34f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
