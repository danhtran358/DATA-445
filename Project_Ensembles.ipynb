{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a5d0518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              1       89             66             23       94  28.1   \n",
       "1              0      137             40             35      168  43.1   \n",
       "2              3       78             50             32       88  31.0   \n",
       "3              2      197             70             45      543  30.5   \n",
       "4              1      189             60             23      846  30.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "387            0      181             88             44      510  43.3   \n",
       "388            1      128             88             39      110  36.5   \n",
       "389            2       88             58             26       16  28.4   \n",
       "390           10      101             76             48      180  32.9   \n",
       "391            5      121             72             23      112  26.2   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.167   21        0  \n",
       "1                       2.288   33        1  \n",
       "2                       0.248   26        1  \n",
       "3                       0.158   53        1  \n",
       "4                       0.398   59        1  \n",
       "..                        ...  ...      ...  \n",
       "387                     0.222   26        1  \n",
       "388                     1.057   37        1  \n",
       "389                     0.766   22        0  \n",
       "390                     0.171   63        0  \n",
       "391                     0.245   30        0  \n",
       "\n",
       "[392 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 6.a\n",
    "import boto3, botocore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from itertools import product\n",
    "\n",
    "## fetch file content from s3\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('danhtran358-data-445-bucket')\n",
    "\n",
    "bucket_object = bucket.Object('project_cleaned_data.csv')\n",
    "## read file content to data-frame\n",
    "diabetes_cleaned = pd.read_csv(bucket_object.get().get('Body'))\n",
    "diabetes_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a78211c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>35</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>23</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>35</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>48</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>27</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>23</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>31</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  SkinThickness   BMI  DiabetesPedigreeFunction  Age  \\\n",
       "0              6      148             35  33.6                     0.627   50   \n",
       "1              1       85             29  26.6                     0.351   31   \n",
       "2              1       89             23  28.1                     0.167   21   \n",
       "3              0      137             35  43.1                     2.288   33   \n",
       "4              3       78             32  31.0                     0.248   26   \n",
       "..           ...      ...            ...   ...                       ...  ...   \n",
       "529            9      170             31  44.0                     0.403   43   \n",
       "530           10      101             48  32.9                     0.171   63   \n",
       "531            2      122             27  36.8                     0.340   27   \n",
       "532            5      121             23  26.2                     0.245   30   \n",
       "533            1       93             31  30.4                     0.315   23   \n",
       "\n",
       "     Outcome  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          1  \n",
       "..       ...  \n",
       "529        1  \n",
       "530        0  \n",
       "531        0  \n",
       "532        0  \n",
       "533        0  \n",
       "\n",
       "[534 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_object = bucket.Object('project_cleaned_data_extended_after_LASSO.csv')\n",
    "## read file content to data-frame\n",
    "diabetes_extended = pd.read_csv(bucket_object.get().get('Body'))\n",
    "diabetes_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "557cd6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to write write data_frame to csv file object in S3 bucket\n",
    "def write_data_to_s3(file_name, data_frame):\n",
    "    ## file object in s3 bucket\n",
    "    data_file = bucket.Object(file_name)\n",
    "    \n",
    "    ## add content from the lists of recall scores\n",
    "    content = data_frame.to_csv(index=False)\n",
    "\n",
    "    ## store as new csv file\n",
    "    data_file.put(Body = content)\n",
    "    \n",
    "\n",
    "## function to read Random Forest data stored in s3 csv to dataframe\n",
    "def read_rf_data(file_name):\n",
    "    try:\n",
    "        ## file object in s3 bucket\n",
    "        rf_data_file = bucket.Object(file_name)\n",
    "        \n",
    "        rf_data_file.load()\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            ## file does not exist yet, create new file\n",
    "            results = expand_grid(rf_dictionary)\n",
    "            \n",
    "            ## will not work on extended data with 8 feature columns\n",
    "            results = results.drop(results[(results['extended_data'] == 'Y') & (results['input_layer'] == 8)].index)\n",
    "            \n",
    "            ## create columns for all types of cut-off values and scores\n",
    "            for i in range(len(cut_off)):\n",
    "                for j in range(len(score_to_evaluate)):\n",
    "                    col = str(cut_off[i]) + '_' + score_to_evaluate[j]\n",
    "                    results[col] = 0.0\n",
    "                    \n",
    "            write_data_to_s3(file_name, results)\n",
    "            \n",
    "            ## return the dataframe from newly created file\n",
    "            return pd.read_csv(rf_data_file.get().get('Body'))\n",
    "    else:\n",
    "        ## return the dataframe already stored\n",
    "        return pd.read_csv(rf_data_file.get().get('Body'))\n",
    "\n",
    "    \n",
    "## function to read AdaBoosting/Gradient Boosting data stored in s3 csv to dataframe\n",
    "def read_boosting_data(file_name):\n",
    "    try:\n",
    "        ## file object in s3 bucket\n",
    "        boosting_data_file = bucket.Object(file_name)\n",
    "        \n",
    "        boosting_data_file.load()\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            ## file does not exist yet, create new file\n",
    "            results = expand_grid(boosting_dictionary)\n",
    "            \n",
    "            ## will not work on extended data with 8 feature columns\n",
    "            results = results.drop(results[(results['extended_data'] == 'Y') & (results['input_layer'] == 8)].index)\n",
    "            \n",
    "            ## create columns for all types of cut-off values and scores\n",
    "            for i in range(len(cut_off)):\n",
    "                for j in range(len(score_to_evaluate)):\n",
    "                    col = str(cut_off[i]) + '_' + score_to_evaluate[j]\n",
    "                    results[col] = 0.0\n",
    "                    \n",
    "            write_data_to_s3(file_name, results)\n",
    "            \n",
    "            ## return the dataframe from newly created file\n",
    "            return pd.read_csv(boosting_data_file.get().get('Body'))\n",
    "    else:\n",
    "        ## return the dataframe already stored\n",
    "        return pd.read_csv(boosting_data_file.get().get('Body'))\n",
    "    \n",
    "\n",
    "## function to read Random Forest data stored in s3 csv to dataframe\n",
    "def read_data_from_s3(file_name, X = None):\n",
    "    try:\n",
    "        ## file object in s3 bucket\n",
    "        data_file = bucket.Object(file_name)\n",
    "        \n",
    "        data_file.load()\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            ## file does not exist yet, create new file\n",
    "            if X is None:\n",
    "                results = expand_grid(dictionary)\n",
    "\n",
    "                ## will not work on extended data with 8 feature columns\n",
    "                results = results.drop(results[(results['extended_data'] == 'Y') & (results['input_layer'] == 8)].index)\n",
    "\n",
    "                ## create columns for all types of cut-off values and scores\n",
    "                for i in range(len(cut_off)):\n",
    "                    for j in range(len(score_to_evaluate)):\n",
    "                        col = str(cut_off[i]) + '_' + score_to_evaluate[j]\n",
    "                        results[col] = 0.0\n",
    "            \n",
    "            else:\n",
    "                ## empty dataframe with first row has 0 for total loops\n",
    "                empty_list = list()\n",
    "                results = pd.DataFrame(empty_list, columns = X.columns)\n",
    "                results.at[0, 'total_loops'] = 0\n",
    "                   \n",
    "            ## write brand new and empty file to s3\n",
    "            write_data_to_s3(file_name, results)\n",
    "            \n",
    "            ## return the dataframe from newly created file\n",
    "            return pd.read_csv(data_file.get().get('Body'))\n",
    "    else:\n",
    "        ## return the dataframe already stored\n",
    "        return pd.read_csv(data_file.get().get('Body'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55a1cc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                    0.067908\n",
      "Glucose                        0.327742\n",
      "BloodPressure                  0.051193\n",
      "SkinThickness                  0.054225\n",
      "Insulin                        0.136200\n",
      "BMI                            0.110167\n",
      "DiabetesPedigreeFunction       0.105079\n",
      "Age                            0.147487\n",
      "total_loops                 1000.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## defining input and target variables\n",
    "X = diabetes_cleaned.drop(columns = ['Outcome'])\n",
    "Y = diabetes_cleaned['Outcome']\n",
    "\n",
    "## List to store feature importances\n",
    "all_feature_importances = list()\n",
    "\n",
    "## read ensemble feature importances data stored in s3 file\n",
    "data_file_name = 'project_ensemble_feature_importances.csv'\n",
    "results = read_data_from_s3(data_file_name, X)\n",
    "\n",
    "for loop_number in range(int(results.at[0, 'total_loops']), 1000):\n",
    "    ## Split data\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "    \n",
    "    ## Build models and store feature importances\n",
    "    md_rf = RandomForestClassifier(max_depth = 3, n_estimators = 500).fit(X_train, Y_train)\n",
    "    all_feature_importances.append(md_rf.feature_importances_)\n",
    "    \n",
    "    md_ada = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = 3), n_estimators = 500, learning_rate = 0.01).fit(X_train, Y_train)\n",
    "    all_feature_importances.append(md_ada.feature_importances_)\n",
    "    \n",
    "    md_grad = GradientBoostingClassifier(max_depth = 3, n_estimators = 500, learning_rate = 0.01).fit(X_train, Y_train)\n",
    "    all_feature_importances.append(md_grad.feature_importances_)\n",
    "    \n",
    "    all_feature_importances_df = pd.DataFrame(all_feature_importances, columns = X.columns)\n",
    "    all_feature_importances_df['total_loops'] = loop_number + 1\n",
    "    \n",
    "    write_data_to_s3(data_file_name, all_feature_importances_df)\n",
    "    \n",
    "## Calculate the average importances of variables across 100 splits and 3 models\n",
    "results = read_data_from_s3(data_file_name, X.columns)\n",
    "print(np.mean(results, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e66db59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>137</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>181</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>128</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>101</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>121</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Glucose  Insulin   BMI  DiabetesPedigreeFunction  Age  Outcome\n",
       "0         89       94  28.1                     0.167   21        0\n",
       "1        137      168  43.1                     2.288   33        1\n",
       "2         78       88  31.0                     0.248   26        1\n",
       "3        197      543  30.5                     0.158   53        1\n",
       "4        189      846  30.1                     0.398   59        1\n",
       "..       ...      ...   ...                       ...  ...      ...\n",
       "387      181      510  43.3                     0.222   26        1\n",
       "388      128      110  36.5                     1.057   37        1\n",
       "389       88       16  28.4                     0.766   22        0\n",
       "390      101      180  32.9                     0.171   63        0\n",
       "391      121      112  26.2                     0.245   30        0\n",
       "\n",
       "[392 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The clean data from project_cleaned_data.csv has missing value observations deleted\n",
    "\n",
    "## This process only cleans missing value observation in the columns kept after dropping less important columns\n",
    "bucket_object = bucket.Object('diabetes.csv')\n",
    "file_object = bucket_object.get()\n",
    "file_content_stream = file_object.get('Body')\n",
    "\n",
    "## read file content to data-frame\n",
    "diabetes_not_cleaned = pd.read_csv(file_content_stream)\n",
    "\n",
    "## dropping columns less important\n",
    "diabetes_important = diabetes_not_cleaned.drop(columns = ['Pregnancies', 'BloodPressure', 'SkinThickness'])\n",
    "\n",
    "## Preprocessing - Clean missing data values\n",
    "## Glucose missing values\n",
    "diabetes_important = diabetes_important.loc[diabetes_important['Glucose'] != 0]\n",
    "\n",
    "## SkinThickness missing values\n",
    "diabetes_important = diabetes_important.loc[diabetes_important['Insulin'] != 0]\n",
    "\n",
    "## BMI missing values\n",
    "diabetes_important = diabetes_important.loc[diabetes_important['BMI'] != 0]\n",
    "\n",
    "diabetes_important = diabetes_important.reset_index(drop = True)\n",
    "\n",
    "diabetes_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76f75b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write cleaned data to s3 bucket\n",
    "write_data_to_s3('project_cleaned_data_extended_after_feature_importances.csv', diabetes_important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ace7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use dataframes to store parameters to build models and store total scores\n",
    "def expand_grid(dictionary):\n",
    "    return pd.DataFrame([row for row in product(*dictionary.values())], columns = dictionary.keys())\n",
    "\n",
    "rf_dictionary = {'extended_data' : ['Y', 'N'], 'input_layer': [5, 6, 8], 'total_loops' : [0],\n",
    "                 'n_tree': [100, 500, 1000, 1500, 2000], 'depth': [3, 5, 7]}\n",
    "boosting_dictionary = {'extended_data' : ['Y', 'N'], 'input_layer': [5, 6, 8], 'total_loops' : [0],\n",
    "                       'n_tree': [100, 500, 1000, 1500, 2000], 'depth': [3, 5, 7], 'learning_rate': [0.1, 0.01, 0.001]}\n",
    "\n",
    "## lists of cut-off values and types of score to evaluate models\n",
    "cut_off = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65]\n",
    "score_to_evaluate = ['precision', 'recall', 'f1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6e980ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## update the scores in result dataset after each model is built\n",
    "def update_result_scores(pred, Y_test, results, combo_number):\n",
    "    \n",
    "    for cut_off_id in range(len(cut_off)):\n",
    "        \n",
    "        ## classify labels\n",
    "        current_cut_off = cut_off[cut_off_id]\n",
    "        pred_labels = np.where(pred < current_cut_off, 0, 1)\n",
    "        \n",
    "        for score_id in range(len(score_to_evaluate)):\n",
    "            \n",
    "            ## updated the appropriate score\n",
    "            current_score = score_to_evaluate[score_id]\n",
    "            score_column = str(current_cut_off) + '_' + current_score\n",
    "            if current_score == 'precision':\n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + precision_score(Y_test, pred_labels, zero_division = 0)\n",
    "            \n",
    "            elif current_score == 'recall':\n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + recall_score(Y_test, pred_labels)\n",
    "                \n",
    "            elif current_score == 'f1': \n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + f1_score(Y_test, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d473fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining input and target variables\n",
    "X = diabetes_cleaned.drop(columns = ['Outcome'])\n",
    "Y = diabetes_cleaned['Outcome']\n",
    "X_lasso = X.drop(columns = ['BloodPressure', 'Insulin'])\n",
    "X_important = X.drop(columns = ['Pregnancies', 'BloodPressure', 'SkinThickness'])\n",
    "X_extended = diabetes_extended.drop(columns = ['Outcome'])\n",
    "Y_extended = diabetes_extended['Outcome']\n",
    "X_important_extended = diabetes_important.drop(columns = ['Outcome'])\n",
    "Y_important_extended = diabetes_important['Outcome']\n",
    "\n",
    "## read Random Forest data stored in s3 file\n",
    "data_file_name = 'project_rf_data.csv'\n",
    "results = read_rf_data(data_file_name)\n",
    "\n",
    "## total_loops column keeps the number of loops already done, we only loop the rest until 100 times done\n",
    "for loop_number in range(results.at[0, 'total_loops'], 100):\n",
    "    \n",
    "    ## Build SVC models for each parameter combination and store scores\n",
    "    for combo_number in range(results.shape[0]):\n",
    "        parameters = results.loc[combo_number]\n",
    "        \n",
    "        if parameters['extended_data'] == 'N':\n",
    "            \n",
    "            if parameters['input_layer'] == 5:\n",
    "                ## cleaned data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_important, Y, test_size = 0.2, stratify = Y)\n",
    "            \n",
    "            elif parameters['input_layer'] == 6:\n",
    "                ## cleaned data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_lasso, Y, test_size = 0.2, stratify = Y)\n",
    "                \n",
    "            elif parameters['input_layer'] == 8:\n",
    "                ## cleaned data with all features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "                \n",
    "        else:\n",
    "        \n",
    "            if parameters['input_layer'] == 5:\n",
    "                ## extended data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_important_extended, Y_important_extended, test_size = 0.2, stratify = Y_important_extended)\n",
    "                \n",
    "            elif parameters['input_layer'] == 6:\n",
    "                ## extended data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_extended, Y_extended, test_size = 0.2, stratify = Y_extended)\n",
    "        \n",
    "        ## Building model\n",
    "        md_rf = RandomForestClassifier(max_depth = parameters['depth'],\n",
    "                                       n_estimators = int(parameters['n_tree'])).fit(X_train, Y_train)\n",
    "\n",
    "        ## Predicting\n",
    "        pred = md_rf.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "        \n",
    "    results['total_loops'] = loop_number + 1\n",
    "    \n",
    "    ## Writing data to s3\n",
    "    write_data_to_s3(data_file_name, results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c876bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4ef4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining input and target variables\n",
    "X = diabetes_cleaned.drop(columns = ['Outcome'])\n",
    "Y = diabetes_cleaned['Outcome']\n",
    "X_lasso = X.drop(columns = ['BloodPressure', 'Insulin'])\n",
    "X_important = X.drop(columns = ['Pregnancies', 'BloodPressure', 'SkinThickness'])\n",
    "X_extended = diabetes_extended.drop(columns = ['Outcome'])\n",
    "Y_extended = diabetes_extended['Outcome']\n",
    "X_important_extended = diabetes_important.drop(columns = ['Outcome'])\n",
    "Y_important_extended = diabetes_important['Outcome']\n",
    "\n",
    "## read Random Forest data stored in s3 file\n",
    "data_file_name = 'project_ada_data.csv'\n",
    "results = read_boosting_data(data_file_name)\n",
    "\n",
    "## total_loops column keeps the number of loops already done, we only loop the rest until 100 times done\n",
    "for loop_number in range(results.at[0, 'total_loops'], 100):\n",
    "    \n",
    "    ## Build SVC models for each parameter combination and store scores\n",
    "    for combo_number in range(results.shape[0]):\n",
    "        parameters = results.loc[combo_number]\n",
    "        \n",
    "        if parameters['extended_data'] == 'N':\n",
    "            \n",
    "            if parameters['input_layer'] == 5:\n",
    "                ## cleaned data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_important, Y, test_size = 0.2, stratify = Y)\n",
    "            \n",
    "            elif parameters['input_layer'] == 6:\n",
    "                ## cleaned data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_lasso, Y, test_size = 0.2, stratify = Y)\n",
    "                \n",
    "            elif parameters['input_layer'] == 8:\n",
    "                ## cleaned data with all features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "                \n",
    "        else:\n",
    "        \n",
    "            if parameters['input_layer'] == 5:\n",
    "                ## extended data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_important_extended, Y_important_extended, test_size = 0.2, stratify = Y_important_extended)\n",
    "                \n",
    "            elif parameters['input_layer'] == 6:\n",
    "                ## extended data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_extended, Y_extended, test_size = 0.2, stratify = Y_extended)\n",
    "        \n",
    "        ## Building model\n",
    "        md_ada = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth = parameters['depth']),\n",
    "                                    n_estimators = int(parameters['n_tree']),\n",
    "                                    learning_rate = parameters['learning_rate']).fit(X_train, Y_train)\n",
    "\n",
    "        ## Predicting\n",
    "        pred = md_ada.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "        \n",
    "    results['total_loops'] = loop_number + 1\n",
    "    \n",
    "    ## Writing data to s3\n",
    "    write_data_to_s3(data_file_name, results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a8098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining input and target variables\n",
    "X = diabetes_cleaned.drop(columns = ['Outcome'])\n",
    "Y = diabetes_cleaned['Outcome']\n",
    "X_lasso = X.drop(columns = ['BloodPressure', 'Insulin'])\n",
    "X_important = X.drop(columns = ['Pregnancies', 'BloodPressure', 'SkinThickness'])\n",
    "X_extended = diabetes_extended.drop(columns = ['Outcome'])\n",
    "Y_extended = diabetes_extended['Outcome']\n",
    "X_important_extended = diabetes_important.drop(columns = ['Outcome'])\n",
    "Y_important_extended = diabetes_important['Outcome']\n",
    "\n",
    "## read Random Forest data stored in s3 file\n",
    "data_file_name = 'project_grad_data.csv'\n",
    "results = read_boosting_data(data_file_name)\n",
    "\n",
    "## total_loops column keeps the number of loops already done, we only loop the rest until 100 times done\n",
    "for loop_number in range(results.at[0, 'total_loops'], 100):\n",
    "    \n",
    "    ## Build SVC models for each parameter combination and store scores\n",
    "    for combo_number in range(results.shape[0]):\n",
    "        parameters = results.loc[combo_number]\n",
    "        \n",
    "        if parameters['extended_data'] == 'N':\n",
    "            \n",
    "            if parameters['input_layer'] == 5:\n",
    "                ## cleaned data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_important, Y, test_size = 0.2, stratify = Y)\n",
    "            \n",
    "            elif parameters['input_layer'] == 6:\n",
    "                ## cleaned data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_lasso, Y, test_size = 0.2, stratify = Y)\n",
    "                \n",
    "            elif parameters['input_layer'] == 8:\n",
    "                ## cleaned data with all features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "                \n",
    "        else:\n",
    "        \n",
    "            if parameters['input_layer'] == 5:\n",
    "                ## extended data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_important_extended, Y_important_extended, test_size = 0.2, stratify = Y_important_extended)\n",
    "                \n",
    "            elif parameters['input_layer'] == 6:\n",
    "                ## extended data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_extended, Y_extended, test_size = 0.2, stratify = Y_extended)\n",
    "        \n",
    "        ## Building model\n",
    "        md_grad = GradientBoostingClassifier(max_depth = parameters['depth'],\n",
    "                                             n_estimators = int(parameters['n_tree']),\n",
    "                                             learning_rate = parameters['learning_rate']).fit(X_train, Y_train)\n",
    "        ## Predicting\n",
    "        pred = md_grad.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "        \n",
    "    results['total_loops'] = loop_number + 1\n",
    "    \n",
    "    ## Writing data to s3\n",
    "    write_data_to_s3(data_file_name, results)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
