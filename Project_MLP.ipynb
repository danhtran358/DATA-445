{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "623529aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.2-cp36-cp36m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 458.3 MB 12 kB/s s eta 0:00:01     |█████████████                   | 186.9 MB 92.3 MB/s eta 0:00:03██████████████▎           | 291.0 MB 82.0 MB/s eta 0:00:03     |█████████████████████████▉      | 369.4 MB 82.0 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Collecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting tensorboard<2.7,>=2.6.0\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 59.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.42.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 60.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py~=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Collecting tensorflow-estimator<2.7,>=2.6.0\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 64.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 6.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 86.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.7,>=2.6.0\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 72.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.19.1)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: cached-property in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.26.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 48.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 81.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 44.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 976 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (58.5.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.7.2)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 81.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.7)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 81.8 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: clang, termcolor\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30693 sha256=c5a7935a8cc576a3750fb8de1211a7708dc1463d48ee0ae9bfed8d969ee37f17\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/22/4c/94/0583f60c9c5b6024ed64f290cb2d43b06bb4f75577dc3c93a7\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=7d7223338ff57651b6d909d35b633bd12678df1f9832858044edd5a4fee6894c\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "Successfully built clang termcolor\n",
      "Installing collected packages: typing-extensions, six, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylint 2.11.1 requires typing-extensions>=3.10.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "astroid 2.8.2 requires typing-extensions>=3.10; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "aiobotocore 1.3.0 requires botocore<1.20.50,>=1.20.49, but you have botocore 1.23.4 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-0.15.0 astunparse-1.6.3 cachetools-4.2.4 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 grpcio-1.42.0 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.6 oauthlib-3.1.1 opt-einsum-3.3.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 six-1.15.0 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.2 tensorflow-estimator-2.6.0 termcolor-1.1.0 typing-extensions-3.7.4.3\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69e1f8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              1       89             66             23       94  28.1   \n",
       "1              0      137             40             35      168  43.1   \n",
       "2              3       78             50             32       88  31.0   \n",
       "3              2      197             70             45      543  30.5   \n",
       "4              1      189             60             23      846  30.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "387            0      181             88             44      510  43.3   \n",
       "388            1      128             88             39      110  36.5   \n",
       "389            2       88             58             26       16  28.4   \n",
       "390           10      101             76             48      180  32.9   \n",
       "391            5      121             72             23      112  26.2   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.167   21        0  \n",
       "1                       2.288   33        1  \n",
       "2                       0.248   26        1  \n",
       "3                       0.158   53        1  \n",
       "4                       0.398   59        1  \n",
       "..                        ...  ...      ...  \n",
       "387                     0.222   26        1  \n",
       "388                     1.057   37        1  \n",
       "389                     0.766   22        0  \n",
       "390                     0.171   63        0  \n",
       "391                     0.245   30        0  \n",
       "\n",
       "[392 rows x 9 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 6.a\n",
    "import boto3, botocore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from itertools import product\n",
    "\n",
    "## fetch file content from s3\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('danhtran358-data-445-bucket')\n",
    "\n",
    "bucket_object = bucket.Object('project_cleaned_data.csv')\n",
    "## read file content to data-frame\n",
    "diabetes_cleaned = pd.read_csv(bucket_object.get().get('Body'))\n",
    "diabetes_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1bb39941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>35</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>23</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>35</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>48</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>27</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>23</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>31</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  SkinThickness   BMI  DiabetesPedigreeFunction  Age  \\\n",
       "0              6      148             35  33.6                     0.627   50   \n",
       "1              1       85             29  26.6                     0.351   31   \n",
       "2              1       89             23  28.1                     0.167   21   \n",
       "3              0      137             35  43.1                     2.288   33   \n",
       "4              3       78             32  31.0                     0.248   26   \n",
       "..           ...      ...            ...   ...                       ...  ...   \n",
       "529            9      170             31  44.0                     0.403   43   \n",
       "530           10      101             48  32.9                     0.171   63   \n",
       "531            2      122             27  36.8                     0.340   27   \n",
       "532            5      121             23  26.2                     0.245   30   \n",
       "533            1       93             31  30.4                     0.315   23   \n",
       "\n",
       "     Outcome  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          1  \n",
       "..       ...  \n",
       "529        1  \n",
       "530        0  \n",
       "531        0  \n",
       "532        0  \n",
       "533        0  \n",
       "\n",
       "[534 rows x 7 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_object = bucket.Object('project_cleaned_data_extended_after_LASSO.csv')\n",
    "## read file content to data-frame\n",
    "diabetes_extended = pd.read_csv(bucket_object.get().get('Body'))\n",
    "diabetes_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a00d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use dataframes to store parameters to build models and store total scores\n",
    "def expand_grid(dictionary):\n",
    "    return pd.DataFrame([row for row in product(*dictionary.values())], columns = dictionary.keys())\n",
    "\n",
    "dictionary = {'extended_data' : ['Y', 'N'], 'input_layer': [6, 8], 'mid_layer_1': [2, 3, 4], 'mid_layer_2': [2, 3, 4], 'total_loops' : [0],\n",
    "                 'batch_size' : [20, 40, 60], 'mlp' : ['mlp1_tanh', 'mlp1_relu', 'mlp2_tanh', 'mlp2_relu', 'mlp2_tanh_relu', 'mlp2_relu_tanh']}\n",
    "\n",
    "## lists of cut-off values and types of score to evaluate models\n",
    "cut_off = [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "score_to_evaluate = ['precision', 'recall', 'f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c0ecc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to write write data_frame to csv file object in S3 bucket\n",
    "def write_data_to_s3(file_name, data_frame):\n",
    "    ## file object in s3 bucket\n",
    "    data_file = bucket.Object(file_name)\n",
    "    \n",
    "    ## add content from the lists of recall scores\n",
    "    content = data_frame.to_csv(index=False)\n",
    "\n",
    "    ## store as new csv file\n",
    "    data_file.put(Body = content)\n",
    "    \n",
    "\n",
    "## function to read Random Forest data stored in s3 csv to dataframe\n",
    "def read_data_from_s3(file_name):\n",
    "    try:\n",
    "        ## file object in s3 bucket\n",
    "        data_file = bucket.Object(file_name)\n",
    "        \n",
    "        data_file.load()\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            ## file does not exist yet, create new file\n",
    "            results = expand_grid(dictionary)\n",
    "            \n",
    "            ## will not work on extended data with 8 feature columns\n",
    "            results = results.drop(results[(results['extended_data'] == 'Y') & (results['input_layer'] == 8)].index)\n",
    "            \n",
    "            ## create columns for all types of cut-off values and scores\n",
    "            for i in range(len(cut_off)):\n",
    "                for j in range(len(score_to_evaluate)):\n",
    "                    col = str(cut_off[i]) + '_' + score_to_evaluate[j]\n",
    "                    results[col] = 0.0\n",
    "                    \n",
    "            ## write brand new and empty file to s3\n",
    "            write_data_to_s3(file_name, results)\n",
    "            \n",
    "            ## return the dataframe from newly created file\n",
    "            return pd.read_csv(data_file.get().get('Body'))\n",
    "    else:\n",
    "        ## return the dataframe already stored\n",
    "        return pd.read_csv(data_file.get().get('Body'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e75ded50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp1_tanh_predict(X_train, X_test, Y_train, input_layer, mid_layer_1, batch_size):\n",
    "    ## Multilayer perceptron 1 mid layer tanh\n",
    "    ## Define mlp structure\n",
    "    mlp_md1 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'tanh'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md1.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    mlp_md1.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "    ## Predict probability \n",
    "    predict_md1 = mlp_md1.predict(X_test)[:,1]\n",
    "    \n",
    "    return predict_md1\n",
    "    \n",
    "\n",
    "def mlp1_relu_predict(X_train, X_test, Y_train, input_layer, mid_layer_1, batch_size):\n",
    "    ## Multilayer perceptron 1 mid layer relu\n",
    "    ## Define mlp structure\n",
    "    mlp_md2 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'relu'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md2.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    mlp_md2.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "    ## Predict probability\n",
    "    predict_md2 = mlp_md2.predict(X_test)[:,1]\n",
    "\n",
    "    return predict_md2\n",
    "\n",
    "\n",
    "def mlp2_tanh_predict(X_train, X_test, Y_train, input_layer, mid_layer_1, mid_layer_2, batch_size):\n",
    "    ## Multilayer perceptron 2 mid layer, both tanh\n",
    "    ## Define mlp structure\n",
    "    mlp_md1 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'tanh'),\n",
    "          tf.keras.layers.Dense(mid_layer_2, activation = 'tanh'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md1.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    mlp_md1.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "    ## Predict probability \n",
    "    predict_md1 = mlp_md1.predict(X_test)[:,1]\n",
    "    \n",
    "    return predict_md1\n",
    "    \n",
    "\n",
    "def mlp2_relu_predict(X_train, X_test, Y_train, input_layer, mid_layer_1, mid_layer_2, batch_size):\n",
    "    ## Multilayer perceptron 2 layers, both relu\n",
    "    ## Define mlp structure\n",
    "    mlp_md2 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'relu'),\n",
    "          tf.keras.layers.Dense(mid_layer_2, activation = 'relu'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md2.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    mlp_md2.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "    ## Predict probability\n",
    "    predict_md2 = mlp_md2.predict(X_test)[:,1]\n",
    "\n",
    "    return predict_md2\n",
    "\n",
    "\n",
    "def mlp2_tanh_relu_predict(X_train, X_test, Y_train, input_layer, mid_layer_1, mid_layer_2, batch_size):\n",
    "    ## Multilayer perceptron 2 layers, tanh and relu\n",
    "    ## Define mlp structure\n",
    "    mlp_md1 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'tanh'),\n",
    "          tf.keras.layers.Dense(mid_layer_2, activation = 'relu'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md1.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    mlp_md1.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "    ## Predict probability \n",
    "    predict_md1 = mlp_md1.predict(X_test)[:,1]\n",
    "    \n",
    "    return predict_md1\n",
    "    \n",
    "\n",
    "def mlp2_relu_tanh_predict(X_train, X_test, Y_train, input_layer, mid_layer_1, mid_layer_2, batch_size):\n",
    "    ## Multilayer perceptron 2 layers, relu and tanh\n",
    "    ## Define mlp structure\n",
    "    mlp_md2 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'relu'),\n",
    "          tf.keras.layers.Dense(mid_layer_2, activation = 'tanh'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md2.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    mlp_md2.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = batch_size, verbose = 0)\n",
    "\n",
    "    ## Predict probability\n",
    "    predict_md2 = mlp_md2.predict(X_test)[:,1]\n",
    "\n",
    "    return predict_md2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a2aa7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build the appropriate model and update the result dataset after each model is built\n",
    "def update_results(X_train, X_test, Y_train, Y_test, results, combo_number):\n",
    "    parameters = results.loc[combo_number]\n",
    "    \n",
    "    if parameters['mlp'] == 'mlp1_tanh':\n",
    "        pred = mlp1_tanh_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'], parameters['batch_size'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "    \n",
    "    elif parameters['mlp'] == 'mlp1_relu':\n",
    "        pred = mlp1_relu_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'], parameters['batch_size'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "    \n",
    "    elif parameters['mlp'] == 'mlp2_tanh':\n",
    "        pred = mlp2_tanh_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'], parameters['mid_layer_2'], parameters['batch_size'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "    \n",
    "    elif parameters['mlp'] == 'mlp2_relu':\n",
    "        pred = mlp2_relu_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'], parameters['mid_layer_2'], parameters['batch_size'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "    \n",
    "    elif parameters['mlp'] == 'mlp2_tanh_relu':\n",
    "        pred = mlp2_tanh_relu_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'], parameters['mid_layer_2'], parameters['batch_size'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "    \n",
    "    elif parameters['mlp'] == 'mlp2_relu_tanh':\n",
    "        pred = mlp2_relu_tanh_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'], parameters['mid_layer_2'], parameters['batch_size'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "\n",
    "## update the scores in result dataset after each model is built\n",
    "def update_result_scores(pred, Y_test, results, combo_number):\n",
    "    for cut_off_id in range(len(cut_off)):\n",
    "        \n",
    "        ## classify labels\n",
    "        current_cut_off = cut_off[cut_off_id]\n",
    "        pred_labels = np.where(pred < current_cut_off, 0, 1)\n",
    "        \n",
    "        for score_id in range(len(score_to_evaluate)):\n",
    "            \n",
    "            ## updated the appropriate score\n",
    "            current_score = score_to_evaluate[score_id]\n",
    "            score_column = str(current_cut_off) + '_' + current_score\n",
    "            \n",
    "            if current_score == 'precision':\n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + precision_score(Y_test, pred_labels, zero_division = 0)\n",
    "            \n",
    "            elif current_score == 'recall':\n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + recall_score(Y_test, pred_labels)\n",
    "                \n",
    "            elif current_score == 'f1': \n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + f1_score(Y_test, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0fb24891",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining input and target variables\n",
    "X = diabetes_cleaned.drop(columns = ['Outcome'])\n",
    "Y = diabetes_cleaned['Outcome']\n",
    "X_lasso = X.drop(columns = ['BloodPressure', 'Insulin'])\n",
    "X_extended = diabetes_extended.drop(columns = ['Outcome'])\n",
    "Y_extended = diabetes_extended['Outcome']\n",
    "\n",
    "## read MLP data stored in s3 file\n",
    "data_file_name = 'project_mlp_result_with_batch.csv'\n",
    "results = read_data_from_s3(data_file_name)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "## total_loops column keeps the number of loops already done, we only loop the rest until 100 times done\n",
    "for loop_number in range(results.at[1, 'total_loops'], 100):\n",
    "    \n",
    "    ## Build MLP models for each parameter combination and store scores\n",
    "    for combo_number in range(results.shape[0]):\n",
    "        parameters = results.loc[combo_number]\n",
    "        \n",
    "        if parameters['extended_data'] == 'N':\n",
    "            \n",
    "            if parameters['input_layer'] == 6:\n",
    "                ## cleaned data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_lasso, Y, test_size = 0.2, stratify = Y)\n",
    "                \n",
    "            else:\n",
    "                ## cleaned data with all features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "                \n",
    "        else:\n",
    "        \n",
    "            if parameters['input_layer'] == 6:\n",
    "                ## extended data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_extended, Y_extended, test_size = 0.2, stratify = Y_extended)\n",
    "                \n",
    "        ## scale input variables to 0-1 scale\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.fit_transform(X_test)\n",
    "        \n",
    "        update_results(X_train, X_test, Y_train, Y_test, results, combo_number)\n",
    "        \n",
    "    results['total_loops'] = loop_number + 1\n",
    "    ## Writing data to s3\n",
    "    write_data_to_s3(data_file_name, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46a6fd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0.2_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.25_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.3_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.35_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.4_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.45_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.5_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>0.639295</td>\n",
       "      <td>146</td>\n",
       "      <td>0.659928</td>\n",
       "      <td>146</td>\n",
       "      <td>0.672734</td>\n",
       "      <td>146</td>\n",
       "      <td>0.674097</td>\n",
       "      <td>146</td>\n",
       "      <td>0.672721</td>\n",
       "      <td>146</td>\n",
       "      <td>0.667687</td>\n",
       "      <td>146</td>\n",
       "      <td>0.656245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>146</td>\n",
       "      <td>0.638058</td>\n",
       "      <td>128</td>\n",
       "      <td>0.658484</td>\n",
       "      <td>128</td>\n",
       "      <td>0.669551</td>\n",
       "      <td>92</td>\n",
       "      <td>0.673442</td>\n",
       "      <td>126</td>\n",
       "      <td>0.669026</td>\n",
       "      <td>92</td>\n",
       "      <td>0.643405</td>\n",
       "      <td>92</td>\n",
       "      <td>0.622597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92</td>\n",
       "      <td>0.627010</td>\n",
       "      <td>92</td>\n",
       "      <td>0.651750</td>\n",
       "      <td>92</td>\n",
       "      <td>0.665469</td>\n",
       "      <td>126</td>\n",
       "      <td>0.671641</td>\n",
       "      <td>128</td>\n",
       "      <td>0.658789</td>\n",
       "      <td>128</td>\n",
       "      <td>0.641986</td>\n",
       "      <td>128</td>\n",
       "      <td>0.618988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148</td>\n",
       "      <td>0.613729</td>\n",
       "      <td>308</td>\n",
       "      <td>0.639769</td>\n",
       "      <td>126</td>\n",
       "      <td>0.657583</td>\n",
       "      <td>128</td>\n",
       "      <td>0.669071</td>\n",
       "      <td>92</td>\n",
       "      <td>0.658009</td>\n",
       "      <td>126</td>\n",
       "      <td>0.638853</td>\n",
       "      <td>108</td>\n",
       "      <td>0.594501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74</td>\n",
       "      <td>0.611754</td>\n",
       "      <td>148</td>\n",
       "      <td>0.638848</td>\n",
       "      <td>144</td>\n",
       "      <td>0.653765</td>\n",
       "      <td>108</td>\n",
       "      <td>0.662456</td>\n",
       "      <td>144</td>\n",
       "      <td>0.653821</td>\n",
       "      <td>108</td>\n",
       "      <td>0.627745</td>\n",
       "      <td>126</td>\n",
       "      <td>0.593631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>169</td>\n",
       "      <td>0.494791</td>\n",
       "      <td>393</td>\n",
       "      <td>0.494942</td>\n",
       "      <td>175</td>\n",
       "      <td>0.498497</td>\n",
       "      <td>333</td>\n",
       "      <td>0.279579</td>\n",
       "      <td>177</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>376</td>\n",
       "      <td>0.084284</td>\n",
       "      <td>340</td>\n",
       "      <td>0.043403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>267</td>\n",
       "      <td>0.494663</td>\n",
       "      <td>301</td>\n",
       "      <td>0.494862</td>\n",
       "      <td>213</td>\n",
       "      <td>0.495894</td>\n",
       "      <td>9</td>\n",
       "      <td>0.265993</td>\n",
       "      <td>171</td>\n",
       "      <td>0.133392</td>\n",
       "      <td>171</td>\n",
       "      <td>0.081072</td>\n",
       "      <td>249</td>\n",
       "      <td>0.040958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>211</td>\n",
       "      <td>0.494600</td>\n",
       "      <td>355</td>\n",
       "      <td>0.494493</td>\n",
       "      <td>211</td>\n",
       "      <td>0.495685</td>\n",
       "      <td>177</td>\n",
       "      <td>0.263322</td>\n",
       "      <td>195</td>\n",
       "      <td>0.131534</td>\n",
       "      <td>195</td>\n",
       "      <td>0.069908</td>\n",
       "      <td>195</td>\n",
       "      <td>0.040151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>391</td>\n",
       "      <td>0.494486</td>\n",
       "      <td>265</td>\n",
       "      <td>0.492863</td>\n",
       "      <td>393</td>\n",
       "      <td>0.494867</td>\n",
       "      <td>171</td>\n",
       "      <td>0.227999</td>\n",
       "      <td>393</td>\n",
       "      <td>0.118358</td>\n",
       "      <td>339</td>\n",
       "      <td>0.058393</td>\n",
       "      <td>376</td>\n",
       "      <td>0.031683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>301</td>\n",
       "      <td>0.493890</td>\n",
       "      <td>211</td>\n",
       "      <td>0.492365</td>\n",
       "      <td>355</td>\n",
       "      <td>0.492157</td>\n",
       "      <td>339</td>\n",
       "      <td>0.219451</td>\n",
       "      <td>339</td>\n",
       "      <td>0.099236</td>\n",
       "      <td>393</td>\n",
       "      <td>0.052892</td>\n",
       "      <td>393</td>\n",
       "      <td>0.028000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>486 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index    0.2_f1  index   0.25_f1  index    0.3_f1  index   0.35_f1  \\\n",
       "0      128  0.639295    146  0.659928    146  0.672734    146  0.674097   \n",
       "1      146  0.638058    128  0.658484    128  0.669551     92  0.673442   \n",
       "2       92  0.627010     92  0.651750     92  0.665469    126  0.671641   \n",
       "3      148  0.613729    308  0.639769    126  0.657583    128  0.669071   \n",
       "4       74  0.611754    148  0.638848    144  0.653765    108  0.662456   \n",
       "..     ...       ...    ...       ...    ...       ...    ...       ...   \n",
       "481    169  0.494791    393  0.494942    175  0.498497    333  0.279579   \n",
       "482    267  0.494663    301  0.494862    213  0.495894      9  0.265993   \n",
       "483    211  0.494600    355  0.494493    211  0.495685    177  0.263322   \n",
       "484    391  0.494486    265  0.492863    393  0.494867    171  0.227999   \n",
       "485    301  0.493890    211  0.492365    355  0.492157    339  0.219451   \n",
       "\n",
       "     index    0.4_f1  index   0.45_f1  index    0.5_f1  \n",
       "0      146  0.672721    146  0.667687    146  0.656245  \n",
       "1      126  0.669026     92  0.643405     92  0.622597  \n",
       "2      128  0.658789    128  0.641986    128  0.618988  \n",
       "3       92  0.658009    126  0.638853    108  0.594501  \n",
       "4      144  0.653821    108  0.627745    126  0.593631  \n",
       "..     ...       ...    ...       ...    ...       ...  \n",
       "481    177  0.158100    376  0.084284    340  0.043403  \n",
       "482    171  0.133392    171  0.081072    249  0.040958  \n",
       "483    195  0.131534    195  0.069908    195  0.040151  \n",
       "484    393  0.118358    339  0.058393    376  0.031683  \n",
       "485    339  0.099236    393  0.052892    393  0.028000  \n",
       "\n",
       "[486 rows x 14 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get number of loops already run\n",
    "loops_run = results.at[0, 'total_loops']\n",
    "\n",
    "## type of score to check\n",
    "score_to_check = 'f1'\n",
    "\n",
    "## Create a dataframe to store values on a cut-off and append values for other cut-offs\n",
    "cut_off_value = cut_off[0]\n",
    "column_name = str(cut_off_value) + '_' + score_to_check\n",
    "\n",
    "all_f1_scores = pd.DataFrame(results[column_name].sort_values(ascending = [False]) / loops_run).reset_index()\n",
    "\n",
    "## Appending cut=offs\n",
    "for cut_off_value in range(1, len(cut_off)):\n",
    "    \n",
    "    column_name = str(cut_off[cut_off_value]) + '_' + score_to_check\n",
    "    next_f1_score = pd.DataFrame(results[column_name].sort_values(ascending = [False]) / loops_run).reset_index()\n",
    "    \n",
    "    all_f1_scores = pd.concat([all_f1_scores, next_f1_score], axis = 1)\n",
    "\n",
    "all_f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f31bc4",
   "metadata": {},
   "source": [
    "## 0.35 looks to be the best cut-off value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f8861179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ext</th>\n",
       "      <th>input</th>\n",
       "      <th>mid1</th>\n",
       "      <th>mid2</th>\n",
       "      <th>batch</th>\n",
       "      <th>mlp</th>\n",
       "      <th>0.3_precision</th>\n",
       "      <th>0.3_recall</th>\n",
       "      <th>0.3_f1</th>\n",
       "      <th>ext</th>\n",
       "      <th>input</th>\n",
       "      <th>mid1</th>\n",
       "      <th>mid2</th>\n",
       "      <th>batch</th>\n",
       "      <th>mlp</th>\n",
       "      <th>0.35_precision</th>\n",
       "      <th>0.35_recall</th>\n",
       "      <th>0.35_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>mlp2_tanh</td>\n",
       "      <td>0.555694</td>\n",
       "      <td>0.867222</td>\n",
       "      <td>0.672734</td>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>mlp2_tanh</td>\n",
       "      <td>0.581090</td>\n",
       "      <td>0.820278</td>\n",
       "      <td>0.674097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>mlp2_tanh</td>\n",
       "      <td>0.563047</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>0.669551</td>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>mlp2_tanh</td>\n",
       "      <td>0.589568</td>\n",
       "      <td>0.809722</td>\n",
       "      <td>0.673442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>mlp2_tanh</td>\n",
       "      <td>0.549435</td>\n",
       "      <td>0.859444</td>\n",
       "      <td>0.665469</td>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>mlp1_tanh</td>\n",
       "      <td>0.581929</td>\n",
       "      <td>0.815556</td>\n",
       "      <td>0.671641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>mlp1_tanh</td>\n",
       "      <td>0.533583</td>\n",
       "      <td>0.878611</td>\n",
       "      <td>0.657583</td>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>mlp2_tanh</td>\n",
       "      <td>0.592055</td>\n",
       "      <td>0.793889</td>\n",
       "      <td>0.669071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>mlp1_tanh</td>\n",
       "      <td>0.534700</td>\n",
       "      <td>0.860556</td>\n",
       "      <td>0.653765</td>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>mlp1_tanh</td>\n",
       "      <td>0.574651</td>\n",
       "      <td>0.801944</td>\n",
       "      <td>0.662456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp1_relu</td>\n",
       "      <td>0.350748</td>\n",
       "      <td>0.903077</td>\n",
       "      <td>0.498497</td>\n",
       "      <td>N</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp2_relu</td>\n",
       "      <td>0.287668</td>\n",
       "      <td>0.326538</td>\n",
       "      <td>0.279579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp2_relu</td>\n",
       "      <td>0.338265</td>\n",
       "      <td>0.946923</td>\n",
       "      <td>0.495894</td>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp2_relu</td>\n",
       "      <td>0.291768</td>\n",
       "      <td>0.303611</td>\n",
       "      <td>0.265993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp1_relu</td>\n",
       "      <td>0.341074</td>\n",
       "      <td>0.931154</td>\n",
       "      <td>0.495685</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp2_relu</td>\n",
       "      <td>0.257620</td>\n",
       "      <td>0.326154</td>\n",
       "      <td>0.263322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>N</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp2_relu</td>\n",
       "      <td>0.336992</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.494867</td>\n",
       "      <td>N</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>mlp2_relu</td>\n",
       "      <td>0.243525</td>\n",
       "      <td>0.253077</td>\n",
       "      <td>0.227999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>N</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp1_relu</td>\n",
       "      <td>0.335898</td>\n",
       "      <td>0.936538</td>\n",
       "      <td>0.492157</td>\n",
       "      <td>N</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>mlp2_relu</td>\n",
       "      <td>0.233533</td>\n",
       "      <td>0.260385</td>\n",
       "      <td>0.219451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>486 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ext  input  mid1  mid2  batch        mlp  0.3_precision  0.3_recall  \\\n",
       "0     Y      6     4     4     20  mlp2_tanh       0.555694    0.867222   \n",
       "1     Y      6     4     3     20  mlp2_tanh       0.563047    0.847500   \n",
       "2     Y      6     3     4     20  mlp2_tanh       0.549435    0.859444   \n",
       "3     Y      6     4     3     20  mlp1_tanh       0.533583    0.878611   \n",
       "4     Y      6     4     4     20  mlp1_tanh       0.534700    0.860556   \n",
       "..   ..    ...   ...   ...    ...        ...            ...         ...   \n",
       "481   N      6     2     2     60  mlp1_relu       0.350748    0.903077   \n",
       "482   N      6     2     4     60  mlp2_relu       0.338265    0.946923   \n",
       "483   N      6     2     4     60  mlp1_relu       0.341074    0.931154   \n",
       "484   N      8     3     2     60  mlp2_relu       0.336992    0.953846   \n",
       "485   N      8     2     3     60  mlp1_relu       0.335898    0.936538   \n",
       "\n",
       "       0.3_f1 ext  input  mid1  mid2  batch        mlp  0.35_precision  \\\n",
       "0    0.672734   Y      6     4     4     20  mlp2_tanh        0.581090   \n",
       "1    0.669551   Y      6     3     4     20  mlp2_tanh        0.589568   \n",
       "2    0.665469   Y      6     4     3     20  mlp1_tanh        0.581929   \n",
       "3    0.657583   Y      6     4     3     20  mlp2_tanh        0.592055   \n",
       "4    0.653765   Y      6     4     2     20  mlp1_tanh        0.574651   \n",
       "..        ...  ..    ...   ...   ...    ...        ...             ...   \n",
       "481  0.498497   N      8     2     2     40  mlp2_relu        0.287668   \n",
       "482  0.495894   Y      6     2     2     40  mlp2_relu        0.291768   \n",
       "483  0.495685   N      6     2     2     60  mlp2_relu        0.257620   \n",
       "484  0.494867   N      6     2     2     40  mlp2_relu        0.243525   \n",
       "485  0.492157   N      8     2     2     60  mlp2_relu        0.233533   \n",
       "\n",
       "     0.35_recall   0.35_f1  \n",
       "0       0.820278  0.674097  \n",
       "1       0.809722  0.673442  \n",
       "2       0.815556  0.671641  \n",
       "3       0.793889  0.669071  \n",
       "4       0.801944  0.662456  \n",
       "..           ...       ...  \n",
       "481     0.326538  0.279579  \n",
       "482     0.303611  0.265993  \n",
       "483     0.326154  0.263322  \n",
       "484     0.253077  0.227999  \n",
       "485     0.260385  0.219451  \n",
       "\n",
       "[486 rows x 18 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Reviewing cut off from above dataframe\n",
    "review_cut_off = [0.3, 0.35]\n",
    "\n",
    "## read MLP data stored in s3 file\n",
    "data_file_name = 'project_mlp_result_with_batch.csv'\n",
    "results = read_data_from_s3(data_file_name)\n",
    "\n",
    "## number of loops already run\n",
    "loops_run = results.at[0, 'total_loops']\n",
    "\n",
    "review_df = pd.DataFrame()\n",
    "\n",
    "## Displaying all average score for the cut-offs chosen to review\n",
    "for cut_off_value in range(len(review_cut_off)):\n",
    "    \n",
    "    column_name = str(review_cut_off[cut_off_value]) + '_f1'\n",
    "    next_f1_score_index = pd.DataFrame(results[column_name].sort_values(ascending = [False])).index\n",
    "    score_columns = list()\n",
    "    \n",
    "    for score_to_check in score_to_evaluate:\n",
    "        \n",
    "        column_name = str(review_cut_off[cut_off_value]) + '_' + score_to_check\n",
    "        \n",
    "        score_columns.append(column_name)\n",
    "\n",
    "    parameter_df = results[['extended_data', 'input_layer', 'mid_layer_1', 'mid_layer_2', 'batch_size', 'mlp']].loc[next_f1_score_index].reset_index(drop = True)\n",
    "    score_df = results[score_columns].loc[next_f1_score_index].reset_index(drop = True) / loops_run\n",
    "    \n",
    "    review_df = pd.concat([review_df, parameter_df, score_df], axis = 1)\n",
    "\n",
    "review_df = review_df.rename(columns = {'extended_data':'ext', 'input_layer':'input', 'mid_layer_1':'mid1', 'mid_layer_2':'mid2', 'batch_size':'batch'})\n",
    "review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e860b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Excluding these results from the project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
