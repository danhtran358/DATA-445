{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92825d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.6.2)\n",
      "Requirement already satisfied: tensorboard<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: clang~=5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: keras<2.7,>=2.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.15.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: cached-property in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (58.5.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.7,>=2.6.0->tensorflow) (3.1.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c2428e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>189</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>846</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.398</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>88</td>\n",
       "      <td>44</td>\n",
       "      <td>510</td>\n",
       "      <td>43.3</td>\n",
       "      <td>0.222</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>88</td>\n",
       "      <td>39</td>\n",
       "      <td>110</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              1       89             66             23       94  28.1   \n",
       "1              0      137             40             35      168  43.1   \n",
       "2              3       78             50             32       88  31.0   \n",
       "3              2      197             70             45      543  30.5   \n",
       "4              1      189             60             23      846  30.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "387            0      181             88             44      510  43.3   \n",
       "388            1      128             88             39      110  36.5   \n",
       "389            2       88             58             26       16  28.4   \n",
       "390           10      101             76             48      180  32.9   \n",
       "391            5      121             72             23      112  26.2   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.167   21        0  \n",
       "1                       2.288   33        1  \n",
       "2                       0.248   26        1  \n",
       "3                       0.158   53        1  \n",
       "4                       0.398   59        1  \n",
       "..                        ...  ...      ...  \n",
       "387                     0.222   26        1  \n",
       "388                     1.057   37        1  \n",
       "389                     0.766   22        0  \n",
       "390                     0.171   63        0  \n",
       "391                     0.245   30        0  \n",
       "\n",
       "[392 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 6.a\n",
    "import boto3, botocore\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from itertools import product\n",
    "\n",
    "## fetch file content from s3\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('danhtran358-data-445-bucket')\n",
    "\n",
    "bucket_object = bucket.Object('project_cleaned_data.csv')\n",
    "## read file content to data-frame\n",
    "diabetes_cleaned = pd.read_csv(bucket_object.get().get('Body'))\n",
    "diabetes_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c7fdd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>35</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>29</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>23</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>35</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>31</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>48</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>27</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>23</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>31</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  SkinThickness   BMI  DiabetesPedigreeFunction  Age  \\\n",
       "0              6      148             35  33.6                     0.627   50   \n",
       "1              1       85             29  26.6                     0.351   31   \n",
       "2              1       89             23  28.1                     0.167   21   \n",
       "3              0      137             35  43.1                     2.288   33   \n",
       "4              3       78             32  31.0                     0.248   26   \n",
       "..           ...      ...            ...   ...                       ...  ...   \n",
       "529            9      170             31  44.0                     0.403   43   \n",
       "530           10      101             48  32.9                     0.171   63   \n",
       "531            2      122             27  36.8                     0.340   27   \n",
       "532            5      121             23  26.2                     0.245   30   \n",
       "533            1       93             31  30.4                     0.315   23   \n",
       "\n",
       "     Outcome  \n",
       "0          1  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          1  \n",
       "..       ...  \n",
       "529        1  \n",
       "530        0  \n",
       "531        0  \n",
       "532        0  \n",
       "533        0  \n",
       "\n",
       "[534 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_object = bucket.Object('project_cleaned_data_extended_after_LASSO.csv')\n",
    "## read file content to data-frame\n",
    "diabetes_extended = pd.read_csv(bucket_object.get().get('Body'))\n",
    "diabetes_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d831d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use dataframes to store parameters to build models and store total scores\n",
    "def expand_grid(dictionary):\n",
    "    return pd.DataFrame([row for row in product(*dictionary.values())], columns = dictionary.keys())\n",
    "\n",
    "dictionary = {'extended_data' : ['Y', 'N'], 'input_layer': [6, 8], 'mid_layer_1': [2, 3, 4], 'mid_layer_2': [2, 3, 4], 'total_loops' : [0],\n",
    "                 'mlp' : ['mlp1_tanh', 'mlp1_relu', 'mlp2_tanh', 'mlp2_relu', 'mlp2_tanh_relu', 'mlp2_relu_tanh']}\n",
    "\n",
    "## lists of cut-off values and types of score to evaluate models\n",
    "cut_off = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35]\n",
    "score_to_evaluate = ['precision', 'recall', 'f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74972efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to write write data_frame to csv file object in S3 bucket\n",
    "def write_data_to_s3(file_name, data_frame):\n",
    "    ## file object in s3 bucket\n",
    "    data_file = bucket.Object(file_name)\n",
    "    \n",
    "    ## add content from the lists of recall scores\n",
    "    content = data_frame.to_csv(index=False)\n",
    "\n",
    "    ## store as new csv file\n",
    "    data_file.put(Body = content)\n",
    "    \n",
    "\n",
    "## function to read Random Forest data stored in s3 csv to dataframe\n",
    "def read_data_from_s3(file_name):\n",
    "    try:\n",
    "        ## file object in s3 bucket\n",
    "        data_file = bucket.Object(file_name)\n",
    "        \n",
    "        data_file.load()\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            ## file does not exist yet, create new file\n",
    "            results = expand_grid(dictionary)\n",
    "            \n",
    "            ## will not work on extended data with 8 feature columns\n",
    "            results = results.drop(results[(results['extended_data'] == 'Y') & (results['input_layer'] == 8)].index)\n",
    "            \n",
    "            ## create columns for all types of cut-off values and scores\n",
    "            for i in range(len(cut_off)):\n",
    "                for j in range(len(score_to_evaluate)):\n",
    "                    col = str(cut_off[i]) + '_' + score_to_evaluate[j]\n",
    "                    results[col] = 0.0\n",
    "                    \n",
    "            ## write brand new and empty file to s3\n",
    "            write_data_to_s3(file_name, results)\n",
    "            \n",
    "            ## return the dataframe from newly created file\n",
    "            return pd.read_csv(data_file.get().get('Body'))\n",
    "    else:\n",
    "        ## return the dataframe already stored\n",
    "        return pd.read_csv(data_file.get().get('Body'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fe30320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp1_tanh_predict(X_train, X_test, Y_train, input_layer, mid_layer_1):\n",
    "    ## Multilayer perceptron 1 mid layer tanh\n",
    "    ## Define mlp structure\n",
    "    mlp_md1 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'tanh'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md1.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    mlp_md1.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = 500, verbose = 0)\n",
    "\n",
    "    ## Predict probability \n",
    "    predict_md1 = mlp_md1.predict(X_test)[:,1]\n",
    "    \n",
    "    return predict_md1\n",
    "    \n",
    "\n",
    "def mlp1_relu_predict(X_train, X_test, Y_train, input_layer, mid_layer_1):\n",
    "    ## Multilayer perceptron 1 mid layer relu\n",
    "    ## Define mlp structure\n",
    "    mlp_md2 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'relu'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md2.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    mlp_md2.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = 500, verbose = 0)\n",
    "\n",
    "    ## Predict probability\n",
    "    predict_md2 = mlp_md2.predict(X_test)[:,1]\n",
    "\n",
    "    return predict_md2\n",
    "\n",
    "\n",
    "def mlp2_tanh_predict(X_train, X_test, Y_train, input_layer, mid_layer_1, mid_layer_2):\n",
    "    ## Multilayer perceptron 2 mid layer, both tanh\n",
    "    ## Define mlp structure\n",
    "    mlp_md1 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'tanh'),\n",
    "          tf.keras.layers.Dense(mid_layer_2, activation = 'tanh'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md1.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    mlp_md1.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = 500, verbose = 0)\n",
    "\n",
    "    ## Predict probability \n",
    "    predict_md1 = mlp_md1.predict(X_test)[:,1]\n",
    "    \n",
    "    return predict_md1\n",
    "    \n",
    "\n",
    "def mlp2_relu_predict(X_train, X_test, Y_train, input_layer, mid_layer_1, mid_layer_2):\n",
    "    ## Multilayer perceptron 2 layers, both relu\n",
    "    ## Define mlp structure\n",
    "    mlp_md2 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'relu'),\n",
    "          tf.keras.layers.Dense(mid_layer_2, activation = 'relu'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md2.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    mlp_md2.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = 500, verbose = 0)\n",
    "\n",
    "    ## Predict probability\n",
    "    predict_md2 = mlp_md2.predict(X_test)[:,1]\n",
    "\n",
    "    return predict_md2\n",
    "\n",
    "\n",
    "def mlp2_tanh_relu_predict(X_train, X_test, Y_train, input_layer, mid_layer_1, mid_layer_2):\n",
    "    ## Multilayer perceptron 2 layers, tanh and relu\n",
    "    ## Define mlp structure\n",
    "    mlp_md1 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'tanh'),\n",
    "          tf.keras.layers.Dense(mid_layer_2, activation = 'relu'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md1.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    mlp_md1.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = 500, verbose = 0)\n",
    "\n",
    "    ## Predict probability \n",
    "    predict_md1 = mlp_md1.predict(X_test)[:,1]\n",
    "    \n",
    "    return predict_md1\n",
    "    \n",
    "\n",
    "def mlp2_relu_tanh_predict(X_train, X_test, Y_train, input_layer, mid_layer_1, mid_layer_2):\n",
    "    ## Multilayer perceptron 2 layers, relu and tanh\n",
    "    ## Define mlp structure\n",
    "    mlp_md2 = tf.keras.models.Sequential([\n",
    "          tf.keras.layers.Dense(mid_layer_1, input_dim = input_layer, activation = 'relu'),\n",
    "          tf.keras.layers.Dense(mid_layer_2, activation = 'tanh'),\n",
    "          tf.keras.layers.Dense(2, activation = 'softmax')\n",
    "    ])\n",
    "\n",
    "    ## Compile and fit model to data\n",
    "    mlp_md2.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    mlp_md2.fit(X_train, tf.keras.utils.to_categorical(Y_train), epochs = 100, batch_size = 500, verbose = 0)\n",
    "\n",
    "    ## Predict probability\n",
    "    predict_md2 = mlp_md2.predict(X_test)[:,1]\n",
    "\n",
    "    return predict_md2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59952ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd42fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build the appropriate model and update the result dataset after each model is built\n",
    "def update_results(X_train, X_test, Y_train, Y_test, results, combo_number):\n",
    "    parameters = results.loc[combo_number]\n",
    "    \n",
    "    if parameters['mlp'] == 'mlp1_tanh':\n",
    "        pred = mlp1_tanh_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "    \n",
    "    elif parameters['mlp'] == 'mlp1_relu':\n",
    "        pred = mlp1_relu_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "    \n",
    "    elif parameters['mlp'] == 'mlp2_tanh':\n",
    "        pred = mlp2_tanh_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'], parameters['mid_layer_2'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "    \n",
    "    elif parameters['mlp'] == 'mlp2_relu':\n",
    "        pred = mlp2_relu_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'], parameters['mid_layer_2'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "    \n",
    "    elif parameters['mlp'] == 'mlp2_tanh_relu':\n",
    "        pred = mlp2_tanh_relu_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'], parameters['mid_layer_2'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "    \n",
    "    elif parameters['mlp'] == 'mlp2_relu_tanh':\n",
    "        pred = mlp2_relu_tanh_predict(X_train, X_test, Y_train, parameters['input_layer'], parameters['mid_layer_1'], parameters['mid_layer_2'])\n",
    "        update_result_scores(pred, Y_test, results, combo_number)\n",
    "\n",
    "## update the scores in result dataset after each model is built\n",
    "def update_result_scores(pred, Y_test, results, combo_number):\n",
    "    for cut_off_id in range(len(cut_off)):\n",
    "        \n",
    "        ## classify labels\n",
    "        current_cut_off = cut_off[cut_off_id]\n",
    "        pred_labels = np.where(pred < current_cut_off, 0, 1)\n",
    "        \n",
    "        for score_id in range(len(score_to_evaluate)):\n",
    "            \n",
    "            ## updated the appropriate score\n",
    "            current_score = score_to_evaluate[score_id]\n",
    "            score_column = str(current_cut_off) + '_' + current_score\n",
    "            \n",
    "            if current_score == 'precision':\n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + precision_score(Y_test, pred_labels, zero_division = 0)\n",
    "            \n",
    "            elif current_score == 'recall':\n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + recall_score(Y_test, pred_labels)\n",
    "                \n",
    "            elif current_score == 'f1': \n",
    "                results.at[combo_number, score_column] = results.at[combo_number, score_column] + f1_score(Y_test, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "823b749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining input and target variables\n",
    "X = diabetes_cleaned.drop(columns = ['Outcome'])\n",
    "Y = diabetes_cleaned['Outcome']\n",
    "X_lasso = X.drop(columns = ['BloodPressure', 'Insulin'])\n",
    "X_extended = diabetes_extended.drop(columns = ['Outcome'])\n",
    "Y_extended = diabetes_extended['Outcome']\n",
    "\n",
    "## read MLP data stored in s3 file\n",
    "data_file_name = 'project_mlp_result.csv'\n",
    "results = read_data_from_s3(data_file_name)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "## total_loops column keeps the number of loops already done, we only loop the rest until 100 times done\n",
    "for loop_number in range(results.at[1, 'total_loops'], 100):\n",
    "    \n",
    "    ## Build MLP models for each parameter combination and store scores\n",
    "    for combo_number in range(results.shape[0]):\n",
    "        parameters = results.loc[combo_number]\n",
    "        \n",
    "        if parameters['extended_data'] == 'N':\n",
    "            \n",
    "            if parameters['input_layer'] == 6:\n",
    "                ## cleaned data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_lasso, Y, test_size = 0.2, stratify = Y)\n",
    "                \n",
    "            else:\n",
    "                ## cleaned data with all features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, stratify = Y)\n",
    "                \n",
    "        else:\n",
    "        \n",
    "            if parameters['input_layer'] == 6:\n",
    "                ## extended data with reduced number of features\n",
    "                X_train, X_test, Y_train, Y_test = train_test_split(X_extended, Y_extended, test_size = 0.2, stratify = Y_extended)\n",
    "                \n",
    "        ## scale input variables to 0-1 scale\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.fit_transform(X_test)\n",
    "        \n",
    "        update_results(X_train, X_test, Y_train, Y_test, results, combo_number)\n",
    "        \n",
    "    results['total_loops'] = loop_number + 1\n",
    "    ## Writing data to s3\n",
    "    write_data_to_s3(data_file_name, results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3189c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.drop(results[(results['extended_data'] == 'Y') & (results['input_layer'] == 8)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66df91a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0.1_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.15_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.2_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.25_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.3_f1</th>\n",
       "      <th>index</th>\n",
       "      <th>0.35_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>0.503958</td>\n",
       "      <td>18</td>\n",
       "      <td>0.504037</td>\n",
       "      <td>205</td>\n",
       "      <td>0.504707</td>\n",
       "      <td>205</td>\n",
       "      <td>0.506943</td>\n",
       "      <td>205</td>\n",
       "      <td>0.507903</td>\n",
       "      <td>205</td>\n",
       "      <td>0.509538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>0.503783</td>\n",
       "      <td>36</td>\n",
       "      <td>0.504017</td>\n",
       "      <td>50</td>\n",
       "      <td>0.504149</td>\n",
       "      <td>187</td>\n",
       "      <td>0.505226</td>\n",
       "      <td>193</td>\n",
       "      <td>0.506390</td>\n",
       "      <td>193</td>\n",
       "      <td>0.508771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>0.503708</td>\n",
       "      <td>43</td>\n",
       "      <td>0.503893</td>\n",
       "      <td>45</td>\n",
       "      <td>0.504021</td>\n",
       "      <td>211</td>\n",
       "      <td>0.504762</td>\n",
       "      <td>199</td>\n",
       "      <td>0.505868</td>\n",
       "      <td>211</td>\n",
       "      <td>0.507764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>0.503649</td>\n",
       "      <td>34</td>\n",
       "      <td>0.503857</td>\n",
       "      <td>43</td>\n",
       "      <td>0.503989</td>\n",
       "      <td>193</td>\n",
       "      <td>0.503905</td>\n",
       "      <td>187</td>\n",
       "      <td>0.504954</td>\n",
       "      <td>199</td>\n",
       "      <td>0.505562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>0.503639</td>\n",
       "      <td>21</td>\n",
       "      <td>0.503790</td>\n",
       "      <td>36</td>\n",
       "      <td>0.503971</td>\n",
       "      <td>199</td>\n",
       "      <td>0.503783</td>\n",
       "      <td>211</td>\n",
       "      <td>0.504285</td>\n",
       "      <td>187</td>\n",
       "      <td>0.505210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>210</td>\n",
       "      <td>0.493482</td>\n",
       "      <td>137</td>\n",
       "      <td>0.490349</td>\n",
       "      <td>191</td>\n",
       "      <td>0.477335</td>\n",
       "      <td>204</td>\n",
       "      <td>0.456300</td>\n",
       "      <td>30</td>\n",
       "      <td>0.399622</td>\n",
       "      <td>24</td>\n",
       "      <td>0.246346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>204</td>\n",
       "      <td>0.492993</td>\n",
       "      <td>192</td>\n",
       "      <td>0.489878</td>\n",
       "      <td>131</td>\n",
       "      <td>0.473941</td>\n",
       "      <td>131</td>\n",
       "      <td>0.454898</td>\n",
       "      <td>174</td>\n",
       "      <td>0.399250</td>\n",
       "      <td>8</td>\n",
       "      <td>0.245246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>186</td>\n",
       "      <td>0.492577</td>\n",
       "      <td>132</td>\n",
       "      <td>0.488476</td>\n",
       "      <td>204</td>\n",
       "      <td>0.472857</td>\n",
       "      <td>114</td>\n",
       "      <td>0.453398</td>\n",
       "      <td>137</td>\n",
       "      <td>0.398347</td>\n",
       "      <td>32</td>\n",
       "      <td>0.225161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>192</td>\n",
       "      <td>0.489920</td>\n",
       "      <td>119</td>\n",
       "      <td>0.485121</td>\n",
       "      <td>174</td>\n",
       "      <td>0.471015</td>\n",
       "      <td>12</td>\n",
       "      <td>0.447581</td>\n",
       "      <td>168</td>\n",
       "      <td>0.393671</td>\n",
       "      <td>42</td>\n",
       "      <td>0.221112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>132</td>\n",
       "      <td>0.489048</td>\n",
       "      <td>174</td>\n",
       "      <td>0.484482</td>\n",
       "      <td>114</td>\n",
       "      <td>0.469971</td>\n",
       "      <td>174</td>\n",
       "      <td>0.439032</td>\n",
       "      <td>114</td>\n",
       "      <td>0.379756</td>\n",
       "      <td>158</td>\n",
       "      <td>0.220435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index    0.1_f1  index   0.15_f1  index    0.2_f1  index   0.25_f1  \\\n",
       "0       36  0.503958     18  0.504037    205  0.504707    205  0.506943   \n",
       "1       21  0.503783     36  0.504017     50  0.504149    187  0.505226   \n",
       "2       18  0.503708     43  0.503893     45  0.504021    211  0.504762   \n",
       "3       11  0.503649     34  0.503857     43  0.503989    193  0.503905   \n",
       "4       22  0.503639     21  0.503790     36  0.503971    199  0.503783   \n",
       "..     ...       ...    ...       ...    ...       ...    ...       ...   \n",
       "157    210  0.493482    137  0.490349    191  0.477335    204  0.456300   \n",
       "158    204  0.492993    192  0.489878    131  0.473941    131  0.454898   \n",
       "159    186  0.492577    132  0.488476    204  0.472857    114  0.453398   \n",
       "160    192  0.489920    119  0.485121    174  0.471015     12  0.447581   \n",
       "161    132  0.489048    174  0.484482    114  0.469971    174  0.439032   \n",
       "\n",
       "     index    0.3_f1  index   0.35_f1  \n",
       "0      205  0.507903    205  0.509538  \n",
       "1      193  0.506390    193  0.508771  \n",
       "2      199  0.505868    211  0.507764  \n",
       "3      187  0.504954    199  0.505562  \n",
       "4      211  0.504285    187  0.505210  \n",
       "..     ...       ...    ...       ...  \n",
       "157     30  0.399622     24  0.246346  \n",
       "158    174  0.399250      8  0.245246  \n",
       "159    137  0.398347     32  0.225161  \n",
       "160    168  0.393671     42  0.221112  \n",
       "161    114  0.379756    158  0.220435  \n",
       "\n",
       "[162 rows x 12 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loops_run = results.at[1, 'total_loops']\n",
    "\n",
    "score_1_f1 = pd.DataFrame(results['0.1_f1'].sort_values(ascending = [False]) / loops_run).reset_index()\n",
    "score_15_f1 = pd.DataFrame(results['0.15_f1'].sort_values(ascending = [False]) / loops_run).reset_index()\n",
    "score_2_f1 = pd.DataFrame(results['0.2_f1'].sort_values(ascending = [False]) / loops_run).reset_index()\n",
    "score_25_f1 = pd.DataFrame(results['0.25_f1'].sort_values(ascending = [False]) / loops_run).reset_index()\n",
    "score_3_f1 = pd.DataFrame(results['0.3_f1'].sort_values(ascending = [False]) / loops_run).reset_index()\n",
    "score_35_f1 = pd.DataFrame(results['0.35_f1'].sort_values(ascending = [False]) / loops_run).reset_index()\n",
    "\n",
    "all_f1_scores = pd.concat([score_1_f1, score_15_f1, score_2_f1, score_25_f1, score_3_f1, score_35_f1], axis = 1)\n",
    "all_f1_scores = all_f1_scores\n",
    "all_f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875a3195",
   "metadata": {},
   "source": [
    "## All models are not better than Logistic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a431b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
